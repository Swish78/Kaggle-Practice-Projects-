{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/swish9/comprehensive-text-data-preprocessing-tutorial?scriptVersionId=143734781\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Objective:\n\nThe primary objective of this notebook is to guide you through the essential steps of data preprocessing for CSV-based data. By the end of this tutorial, you should be proficient in importing data, exploring datasets, handling missing values, detecting and removing outliers, encoding categorical variables, and normalizing numeric features.","metadata":{}},{"cell_type":"markdown","source":"# Notebook Content\n\n\n1. **Importing Libraries:**\n   - Begin by importing the necessary Python libraries, such as Pandas, NumPy, and scikit-learn, for data preprocessing.\n\n2. **Importing Dataset:**\n   - Load your CSV-based dataset into a Pandas DataFrame for further analysis.\n\n3. **Exploring the Dataset:**\n   - Some of the Pandas functions used here to explore and understand the dataset are:\n     - `head()`: Display the first few rows of the DataFrame.\n     - `tail()`: Display the last few rows of the DataFrame.\n     - `duplicated()`: Identify duplicate rows in the DataFrame.\n     - `drop_duplicates()`: Remove duplicate rows.\n     - `describe()`: Provide summary statistics of numeric columns.\n     - `info()`: Display information about the DataFrame, including data types and missing values.\n\n4. **Handling Missing Values:**\n   - Address missing values in both categorical and numeric columns using appropriate techniques (e.g., imputation, removal).\n\n5. **Outlier Detection and Removal:**\n   - Identify and handle outliers in numeric columns using visualizations (e.g., box plots) and suitable methods (e.g., removing or transforming outliers).\n\n6. **Encoding Categorical Variables:**\n   - Encode categorical variables using one-hot encoding or label encoding, depending on the nature of the data.\n\n7. **Normalizing Numeric Features:**\n   - Normalize numeric features using techniques like Min-Max Scaling or Standardization.\n\n8. **Conclusion and Next Steps:**\n   - Summarize the key takeaways from the notebook.\n   - Suggest further preprocessing steps or additional analysis that can be performed on the cleaned dataset.","metadata":{}},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd  # Data manipulation\nimport numpy as np  # Numerical operations\nimport matplotlib.pyplot as plt  # Data visualization\nimport seaborn as sns  # Enhanced data visualization\nfrom sklearn.model_selection import train_test_split  # Data splitting\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler, StandardScaler # Data preprocessing\nfrom sklearn.impute import SimpleImputer # Data preprocessing\nfrom scipy import stats # statistics","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-21T08:45:16.133956Z","iopub.execute_input":"2023-09-21T08:45:16.134372Z","iopub.status.idle":"2023-09-21T08:45:18.044328Z","shell.execute_reply.started":"2023-09-21T08:45:16.134338Z","shell.execute_reply":"2023-09-21T08:45:18.042088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing Dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/d/sycoc189sairajpawar/students-exam-scores/Expanded_data_with_more_features.csv') # Importing dataset ","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:18.047051Z","iopub.execute_input":"2023-09-21T08:45:18.048251Z","iopub.status.idle":"2023-09-21T08:45:18.198484Z","shell.execute_reply.started":"2023-09-21T08:45:18.048201Z","shell.execute_reply":"2023-09-21T08:45:18.197316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Basic Dataset Exploration ","metadata":{}},{"cell_type":"code","source":"df.head()  # Display the first 5 rows of the DataFrame","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:18.202028Z","iopub.execute_input":"2023-09-21T08:45:18.202973Z","iopub.status.idle":"2023-09-21T08:45:18.246463Z","shell.execute_reply.started":"2023-09-21T08:45:18.202919Z","shell.execute_reply":"2023-09-21T08:45:18.24536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.tail()  # Display the last 5 rows of the DataFrame","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:18.251708Z","iopub.execute_input":"2023-09-21T08:45:18.252222Z","iopub.status.idle":"2023-09-21T08:45:18.272201Z","shell.execute_reply.started":"2023-09-21T08:45:18.252188Z","shell.execute_reply":"2023-09-21T08:45:18.271078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.sample(n=5)  # Display the random n rows of the DataFrame","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:18.273948Z","iopub.execute_input":"2023-09-21T08:45:18.274649Z","iopub.status.idle":"2023-09-21T08:45:18.310906Z","shell.execute_reply.started":"2023-09-21T08:45:18.274602Z","shell.execute_reply":"2023-09-21T08:45:18.309785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_rows, num_columns = df.shape\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:18.312595Z","iopub.execute_input":"2023-09-21T08:45:18.313715Z","iopub.status.idle":"2023-09-21T08:45:18.321384Z","shell.execute_reply.started":"2023-09-21T08:45:18.313674Z","shell.execute_reply":"2023-09-21T08:45:18.320007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns # Display column name ","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:18.322983Z","iopub.execute_input":"2023-09-21T08:45:18.323384Z","iopub.status.idle":"2023-09-21T08:45:18.335566Z","shell.execute_reply.started":"2023-09-21T08:45:18.323341Z","shell.execute_reply":"2023-09-21T08:45:18.334439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One-line explanation for each column in the provided DataFrame:\n\n1. **'Unnamed: 0'**: Likely an index or identifier column.\n2. **'Gender'**: Gender of the student (e.g., male or female).\n3. **'EthnicGroup'**: Ethnic group or background of the student.\n4. **'ParentEduc'**: Education level of the student's parent(s).\n5. **'LunchType'**: Type of lunch the student receives (e.g., free/reduced or standard).\n6. **'TestPrep'**: Whether the student completed test preparation (e.g., yes or no).\n7. **'ParentMaritalStatus'**: Marital status of the student's parent(s).\n8. **'PracticeSport'**: Whether the student practices a sport (e.g., yes or no).\n9. **'IsFirstChild'**: Whether the student is the first child in the family (e.g., yes or no).\n10. **'NrSiblings'**: Number of siblings the student has.\n11. **'TransportMeans'**: Means of transportation to school (e.g., bus, car, etc.).\n12. **'WklyStudyHours'**: Number of weekly study hours.\n13. **'MathScore'**: Score in the math exam.\n14. **'ReadingScore'**: Score in the reading exam.\n15. **'WritingScore'**: Score in the writing exam.","metadata":{}},{"cell_type":"code","source":"df.describe(include='all').T # statistics","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:18.336986Z","iopub.execute_input":"2023-09-21T08:45:18.337674Z","iopub.status.idle":"2023-09-21T08:45:18.49515Z","shell.execute_reply.started":"2023-09-21T08:45:18.337634Z","shell.execute_reply":"2023-09-21T08:45:18.494068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes # Display Datatypes of columns","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:18.496767Z","iopub.execute_input":"2023-09-21T08:45:18.497468Z","iopub.status.idle":"2023-09-21T08:45:18.506921Z","shell.execute_reply.started":"2023-09-21T08:45:18.497429Z","shell.execute_reply":"2023-09-21T08:45:18.505815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.count() # Display non-null values","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:18.512576Z","iopub.execute_input":"2023-09-21T08:45:18.513357Z","iopub.status.idle":"2023-09-21T08:45:18.559122Z","shell.execute_reply.started":"2023-09-21T08:45:18.513302Z","shell.execute_reply":"2023-09-21T08:45:18.558306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df.isna()] # Display null rows","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:18.560323Z","iopub.execute_input":"2023-09-21T08:45:18.560836Z","iopub.status.idle":"2023-09-21T08:45:18.636289Z","shell.execute_reply.started":"2023-09-21T08:45:18.560785Z","shell.execute_reply":"2023-09-21T08:45:18.635208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum() # Display null values","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:18.637897Z","iopub.execute_input":"2023-09-21T08:45:18.638255Z","iopub.status.idle":"2023-09-21T08:45:18.67914Z","shell.execute_reply.started":"2023-09-21T08:45:18.638225Z","shell.execute_reply":"2023-09-21T08:45:18.678017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.nunique() # Display Count of Unique Values in a Columns","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:18.680466Z","iopub.execute_input":"2023-09-21T08:45:18.681659Z","iopub.status.idle":"2023-09-21T08:45:18.723016Z","shell.execute_reply.started":"2023-09-21T08:45:18.681613Z","shell.execute_reply":"2023-09-21T08:45:18.721864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.duplicated().sum() # Display Count of Duplicated Values in a Datafram","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:18.724839Z","iopub.execute_input":"2023-09-21T08:45:18.72559Z","iopub.status.idle":"2023-09-21T08:45:18.79177Z","shell.execute_reply.started":"2023-09-21T08:45:18.725544Z","shell.execute_reply":"2023-09-21T08:45:18.790966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop_duplicates() # Dropping Duplicates","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:18.793253Z","iopub.execute_input":"2023-09-21T08:45:18.793861Z","iopub.status.idle":"2023-09-21T08:45:18.855427Z","shell.execute_reply.started":"2023-09-21T08:45:18.793829Z","shell.execute_reply":"2023-09-21T08:45:18.854564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:18.857154Z","iopub.execute_input":"2023-09-21T08:45:18.857887Z","iopub.status.idle":"2023-09-21T08:45:18.923245Z","shell.execute_reply.started":"2023-09-21T08:45:18.857842Z","shell.execute_reply":"2023-09-21T08:45:18.921891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info() # Display info about the Datafrme","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:18.926571Z","iopub.execute_input":"2023-09-21T08:45:18.927067Z","iopub.status.idle":"2023-09-21T08:45:18.983416Z","shell.execute_reply.started":"2023-09-21T08:45:18.92702Z","shell.execute_reply":"2023-09-21T08:45:18.982098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing ","metadata":{}},{"cell_type":"code","source":"categorical_cols = df.select_dtypes(include=['object']).columns # Selecting categorical columns \nnumeric_cols = df.select_dtypes(include=[np.number]).columns # Selecting numerical columns ","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:18.984741Z","iopub.execute_input":"2023-09-21T08:45:18.985101Z","iopub.status.idle":"2023-09-21T08:45:18.994258Z","shell.execute_reply.started":"2023-09-21T08:45:18.985067Z","shell.execute_reply":"2023-09-21T08:45:18.993064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape[1]","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:18.99574Z","iopub.execute_input":"2023-09-21T08:45:18.996825Z","iopub.status.idle":"2023-09-21T08:45:19.013062Z","shell.execute_reply.started":"2023-09-21T08:45:18.996755Z","shell.execute_reply":"2023-09-21T08:45:19.01136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(categorical_cols)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:19.014583Z","iopub.execute_input":"2023-09-21T08:45:19.015058Z","iopub.status.idle":"2023-09-21T08:45:19.027992Z","shell.execute_reply.started":"2023-09-21T08:45:19.015015Z","shell.execute_reply":"2023-09-21T08:45:19.026542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(numeric_cols)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:19.02962Z","iopub.execute_input":"2023-09-21T08:45:19.030076Z","iopub.status.idle":"2023-09-21T08:45:19.044268Z","shell.execute_reply.started":"2023-09-21T08:45:19.030031Z","shell.execute_reply":"2023-09-21T08:45:19.043374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Handling Categorical Missing Values**","metadata":{}},{"cell_type":"code","source":"categorical_imputer = SimpleImputer(strategy='most_frequent')","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:19.045581Z","iopub.execute_input":"2023-09-21T08:45:19.045948Z","iopub.status.idle":"2023-09-21T08:45:19.057979Z","shell.execute_reply.started":"2023-09-21T08:45:19.045917Z","shell.execute_reply":"2023-09-21T08:45:19.056989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SimpleImputer(strategy='most_frequent')** is a data preprocessing technique that replaces missing values in a dataset with the most frequent value (mode) for each respective column. It's often used for categorical data where missing values are replaced with the category that occurs most frequently in that column.","metadata":{}},{"cell_type":"code","source":"df[categorical_cols] = categorical_imputer.fit_transform(df[categorical_cols])","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:19.059198Z","iopub.execute_input":"2023-09-21T08:45:19.059632Z","iopub.status.idle":"2023-09-21T08:45:19.147597Z","shell.execute_reply.started":"2023-09-21T08:45:19.059591Z","shell.execute_reply":"2023-09-21T08:45:19.14628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[categorical_cols].isnull().sum() # Varifying if categorical missing values are handled well","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:19.148604Z","iopub.execute_input":"2023-09-21T08:45:19.148933Z","iopub.status.idle":"2023-09-21T08:45:19.202983Z","shell.execute_reply.started":"2023-09-21T08:45:19.148905Z","shell.execute_reply":"2023-09-21T08:45:19.201812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Handling Numerical Missing Values**","metadata":{}},{"cell_type":"code","source":"# This is standard approach but it will also outliers i.e. extremely outperforming values which kinda will add noise to data\n# numeric_imputer = SimpleImputer(strategy='mean')\n# data[numeric_cols] = numeric_imputer.fit_transform(data[numeric_cols])\n\n# So we'll be using Trimmed mean approach for handling numeric values \n\nfor col in numeric_cols:\n    # Calculate the trimmed mean (5%)\n    trimmed_mean = stats.trim_mean(df[col].dropna(), proportiontocut=0.05)\n    df[col].fillna(trimmed_mean, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:19.20429Z","iopub.execute_input":"2023-09-21T08:45:19.204616Z","iopub.status.idle":"2023-09-21T08:45:19.217195Z","shell.execute_reply.started":"2023-09-21T08:45:19.204588Z","shell.execute_reply":"2023-09-21T08:45:19.215742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using a trimmed mean (e.g., 5%) instead of a simple imputer mean strategy is preferred when you want to:\n\n1. **Reduce Outlier Influence:** Mitigate the impact of outliers or extreme values on the central tendency measure.\n   \n2. **Preserve Data Distribution:** Retain more information about the underlying data distribution.\n\n3. **Fine-Tune Trimming:** Have control over the percentage of data points to trim, allowing customization based on your dataset characteristics.","metadata":{}},{"cell_type":"code","source":"df[numeric_cols].isnull().sum() # Varifying if categorical missing values are handled well","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:19.219233Z","iopub.execute_input":"2023-09-21T08:45:19.219601Z","iopub.status.idle":"2023-09-21T08:45:19.239519Z","shell.execute_reply.started":"2023-09-21T08:45:19.219568Z","shell.execute_reply":"2023-09-21T08:45:19.238091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Encoding Categorical features**","metadata":{}},{"cell_type":"code","source":"# Initialize the OneHotEncoder with drop='first'\nencoder = OneHotEncoder(drop='first', sparse_output=False)\n# ‘first’ : drop the first category in each feature.\n# sparse_output: Will return sparse matrix if set True else will return an array.","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:19.241021Z","iopub.execute_input":"2023-09-21T08:45:19.241476Z","iopub.status.idle":"2023-09-21T08:45:19.250449Z","shell.execute_reply.started":"2023-09-21T08:45:19.241432Z","shell.execute_reply":"2023-09-21T08:45:19.249086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One-Hot Encoding (OHE) with \"drop first\" is a variation of OHE where one category is dropped to avoid multicollinearity, which can occur when you have binary columns that are perfectly correlated. \n\nHere's how it works:\n\n- If you have a categorical feature with `n` categories, OHE without \"drop first\" would create `n` binary columns.\n\n- OHE with \"drop first\" creates only `n - 1` binary columns. It drops one category (usually the first) and represents it indirectly through the absence of all the other categories being 1.\n\n**Example:**\n\nLet's say you have a categorical feature \"Color\" with three categories: Red, Blue, and Green.\n\nWithout \"drop first,\" OHE creates three binary columns:\n\n- Red: 1 if the color is Red, 0 otherwise.\n- Blue: 1 if the color is Blue, 0 otherwise.\n- Green: 1 if the color is Green, 0 otherwise.\n\nWith \"drop first,\" OHE creates two binary columns:\n\n- Blue: 1 if the color is Blue, 0 otherwise.\n- Green: 1 if the color is Green, 0 otherwise.\n\nIn this example, the absence of both Blue and Green being 1 implies that the color is Red. So, you can represent all three categories with two binary columns instead of three, which can be useful for some machine learning algorithms.","metadata":{}},{"cell_type":"code","source":"# Fit and transform the encoder on categorical columns\nencoded_cols = encoder.fit_transform(df[categorical_cols])","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:19.259187Z","iopub.execute_input":"2023-09-21T08:45:19.259643Z","iopub.status.idle":"2023-09-21T08:45:19.461294Z","shell.execute_reply.started":"2023-09-21T08:45:19.259573Z","shell.execute_reply":"2023-09-21T08:45:19.460087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a DataFrame from the encoded columns\nencoded_df = pd.DataFrame(encoded_cols, columns=encoder.get_feature_names_out(categorical_cols))\n#  concatenates encoded feature name and category with feature + \"_\" + str(category).E.g. feature X with values 1, 6, 7 create feature names X_1, X_6, X_7","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:19.462564Z","iopub.execute_input":"2023-09-21T08:45:19.463022Z","iopub.status.idle":"2023-09-21T08:45:19.468938Z","shell.execute_reply.started":"2023-09-21T08:45:19.462981Z","shell.execute_reply":"2023-09-21T08:45:19.467834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop the original categorical columns from the original DataFrame\ndf.drop(categorical_cols, axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:19.470598Z","iopub.execute_input":"2023-09-21T08:45:19.471546Z","iopub.status.idle":"2023-09-21T08:45:19.48534Z","shell.execute_reply.started":"2023-09-21T08:45:19.471506Z","shell.execute_reply":"2023-09-21T08:45:19.48428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Concatenate the original DataFrame with the encoded DataFrame\ndf = pd.concat([df, encoded_df], axis=1)\ndf.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:19.487555Z","iopub.execute_input":"2023-09-21T08:45:19.488252Z","iopub.status.idle":"2023-09-21T08:45:19.528363Z","shell.execute_reply.started":"2023-09-21T08:45:19.488209Z","shell.execute_reply":"2023-09-21T08:45:19.527196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes # Verifying the encoding procedure ","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:19.530135Z","iopub.execute_input":"2023-09-21T08:45:19.530595Z","iopub.status.idle":"2023-09-21T08:45:19.540091Z","shell.execute_reply.started":"2023-09-21T08:45:19.530527Z","shell.execute_reply":"2023-09-21T08:45:19.538646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Outlier Detection**","metadata":{}},{"cell_type":"markdown","source":"**Outliers** are data points that significantly differ from the rest of the observations in a dataset. They can be exceptionally high or low values compared to the majority of data points.\n\n**Why Remove Outliers:**\n\nOutliers can distort statistical analyses and models, leading to biased results.\nThey can skew the mean and standard deviation, affecting the overall data distribution.\nSome machine learning algorithms are sensitive to outliers, impacting their performance.\nOutliers can represent data errors or anomalies that may not reflect the true underlying patterns.","metadata":{}},{"cell_type":"code","source":"df.mean()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:19.541585Z","iopub.execute_input":"2023-09-21T08:45:19.541934Z","iopub.status.idle":"2023-09-21T08:45:19.559618Z","shell.execute_reply.started":"2023-09-21T08:45:19.541905Z","shell.execute_reply":"2023-09-21T08:45:19.558408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16, 10))\nplt.subplot(1, 2, 1)\nsns.boxplot(data=df, orient=\"h\")","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:19.561868Z","iopub.execute_input":"2023-09-21T08:45:19.562959Z","iopub.status.idle":"2023-09-21T08:45:20.620569Z","shell.execute_reply.started":"2023-09-21T08:45:19.56292Z","shell.execute_reply":"2023-09-21T08:45:20.619358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create subplots for violin plots\nplt.figure(figsize=(16, 10))\nplt.subplot(1, 2, 2)\nsns.violinplot(data=df, orient=\"h\", inner=\"quart\") ","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:20.62253Z","iopub.execute_input":"2023-09-21T08:45:20.623634Z","iopub.status.idle":"2023-09-21T08:45:24.651188Z","shell.execute_reply.started":"2023-09-21T08:45:20.623586Z","shell.execute_reply":"2023-09-21T08:45:24.649898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**For removing outliers we'll be using z-score technique**","metadata":{}},{"cell_type":"code","source":"threshold = 2 # The threshold variable is set to a value that determines how far away from the mean is considered an outlier\ndf = df[(np.abs(df - df.mean()) < threshold * df.std()).all(axis=1)] # (x - mean) / std represents the z-score or standard score of a data point x in a dataset.","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:24.652617Z","iopub.execute_input":"2023-09-21T08:45:24.652995Z","iopub.status.idle":"2023-09-21T08:45:24.683282Z","shell.execute_reply.started":"2023-09-21T08:45:24.652964Z","shell.execute_reply":"2023-09-21T08:45:24.681768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.mean()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:24.684917Z","iopub.execute_input":"2023-09-21T08:45:24.685265Z","iopub.status.idle":"2023-09-21T08:45:24.698183Z","shell.execute_reply.started":"2023-09-21T08:45:24.685236Z","shell.execute_reply":"2023-09-21T08:45:24.696931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Normalizing Data**","metadata":{}},{"cell_type":"code","source":"# Initialize the MinMaxScaler\nMMS = MinMaxScaler()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:24.699775Z","iopub.execute_input":"2023-09-21T08:45:24.700182Z","iopub.status.idle":"2023-09-21T08:45:24.706567Z","shell.execute_reply.started":"2023-09-21T08:45:24.700151Z","shell.execute_reply":"2023-09-21T08:45:24.705271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**MinMaxScaler** is a data preprocessing technique used to transform numeric data, typically features, into a specific range, usually between 0 and 1. It scales and shifts the original values so that they fall within this specified range while maintaining their relative relationships.\n\nHere's a brief explanation:\n\n- **Scaling Range**: MinMaxScaler scales the original data within a specified range, often between 0 and 1, but you can adjust this range as needed.\n\n- **Formula**: It uses the following formula to transform each data point `X` to its scaled counterpart `X_scaled`:\n\n  ```\n  X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n  X_scaled = X_std * (max - min) + min\n  \n  ```\n\n\n  Where `X_min` is the minimum value in the original dataset, and `X_max` is the maximum value.\n\n- **Normalization**: MinMax scaling is a form of normalization that makes the data more suitable for machine learning algorithms that are sensitive to the scale of the features. It preserves the relationships between data points and maintains the data's distribution.\n\n**Example**:\n\nSuppose you have a dataset with a feature \"Age,\" and the ages range from 20 to 60. By applying MinMaxScaler with a range of 0 to 1:\n\n- Age 20 would be scaled to 0.\n- Age 60 would be scaled to 1.\n- Ages in between 20 and 60 would be scaled proportionally between 0 and 1, preserving their relative positions.\n\nMinMaxScaler is commonly used when you want to ensure that different features have the same scale, especially in machine learning algorithms like support vector machines (SVM) or k-nearest neighbors (KNN), where the scale of features can impact the results.","metadata":{}},{"cell_type":"code","source":"# Fit and transform the scaler on numeric columns\ndf[numeric_cols] = MMS.fit_transform(df[numeric_cols])","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:24.708676Z","iopub.execute_input":"2023-09-21T08:45:24.709153Z","iopub.status.idle":"2023-09-21T08:45:24.726913Z","shell.execute_reply.started":"2023-09-21T08:45:24.709113Z","shell.execute_reply":"2023-09-21T08:45:24.725742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:24.728226Z","iopub.execute_input":"2023-09-21T08:45:24.729304Z","iopub.status.idle":"2023-09-21T08:45:24.761853Z","shell.execute_reply.started":"2023-09-21T08:45:24.729267Z","shell.execute_reply":"2023-09-21T08:45:24.760846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe(include='all').T # vering the normalization","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:24.763028Z","iopub.execute_input":"2023-09-21T08:45:24.763789Z","iopub.status.idle":"2023-09-21T08:45:24.857271Z","shell.execute_reply.started":"2023-09-21T08:45:24.763756Z","shell.execute_reply":"2023-09-21T08:45:24.855945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.corr()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T08:45:24.859137Z","iopub.execute_input":"2023-09-21T08:45:24.859884Z","iopub.status.idle":"2023-09-21T08:45:24.922106Z","shell.execute_reply.started":"2023-09-21T08:45:24.859842Z","shell.execute_reply":"2023-09-21T08:45:24.921038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\n\n**In conclusion, this comprehensive CSV data preprocessing tutorial has covered essential steps to prepare your dataset for analysis, visualization, and machine learning applications.** ","metadata":{}}]}