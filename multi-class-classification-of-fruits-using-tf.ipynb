{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-09-01T17:07:33.331682Z","iopub.execute_input":"2023-09-01T17:07:33.332363Z","iopub.status.idle":"2023-09-01T17:07:33.363209Z","shell.execute_reply.started":"2023-09-01T17:07:33.332316Z","shell.execute_reply":"2023-09-01T17:07:33.362059Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\nfrom tensorflow.keras.initializers import GlorotNormal","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-01T17:07:33.364630Z","iopub.execute_input":"2023-09-01T17:07:33.364962Z","iopub.status.idle":"2023-09-01T17:07:42.651984Z","shell.execute_reply.started":"2023-09-01T17:07:33.364935Z","shell.execute_reply":"2023-09-01T17:07:42.650815Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_dir = '/kaggle/input/fruits-dataset-images/images'","metadata":{"execution":{"iopub.status.busy":"2023-09-01T17:07:42.653922Z","iopub.execute_input":"2023-09-01T17:07:42.654614Z","iopub.status.idle":"2023-09-01T17:07:42.658858Z","shell.execute_reply.started":"2023-09-01T17:07:42.654577Z","shell.execute_reply":"2023-09-01T17:07:42.658044Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1.0/255,\n    rotation_range=10,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-01T17:07:42.659829Z","iopub.execute_input":"2023-09-01T17:07:42.660682Z","iopub.status.idle":"2023-09-01T17:07:42.699375Z","shell.execute_reply.started":"2023-09-01T17:07:42.660639Z","shell.execute_reply":"2023-09-01T17:07:42.698226Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='categorical'\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-01T17:07:42.702331Z","iopub.execute_input":"2023-09-01T17:07:42.702775Z","iopub.status.idle":"2023-09-01T17:07:42.747073Z","shell.execute_reply.started":"2023-09-01T17:07:42.702731Z","shell.execute_reply":"2023-09-01T17:07:42.746154Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Found 359 images belonging to 9 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"model = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n    MaxPooling2D(2, 2),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D(2, 2),\n    Conv2D(128, (3, 3), activation='relu'),\n    MaxPooling2D(2, 2),\n    Flatten(),\n    Dense(512, activation='relu'),\n    Dense(9, activation='softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2023-09-01T17:07:42.748262Z","iopub.execute_input":"2023-09-01T17:07:42.748535Z","iopub.status.idle":"2023-09-01T17:07:43.148806Z","shell.execute_reply.started":"2023-09-01T17:07:42.748510Z","shell.execute_reply":"2023-09-01T17:07:43.147671Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"**I tried using He and Glorot Initialization techniques for weights, but I was getting accuracies around 0.6 to 0.7. However, with random initialization, my highest accuracy was 0.84**","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-09-01T17:07:43.150202Z","iopub.execute_input":"2023-09-01T17:07:43.150517Z","iopub.status.idle":"2023-09-01T17:07:43.172448Z","shell.execute_reply.started":"2023-09-01T17:07:43.150490Z","shell.execute_reply":"2023-09-01T17:07:43.171079Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"num_epochs = 10\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=len(train_generator),\n    epochs=num_epochs,\n    verbose=1\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-01T17:11:55.928619Z","iopub.execute_input":"2023-09-01T17:11:55.929115Z","iopub.status.idle":"2023-09-01T17:15:21.825714Z","shell.execute_reply.started":"2023-09-01T17:11:55.929077Z","shell.execute_reply":"2023-09-01T17:15:21.824837Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 1/10\n12/12 [==============================] - 20s 2s/step - loss: 1.1279 - accuracy: 0.6156\nEpoch 2/10\n12/12 [==============================] - 20s 2s/step - loss: 0.9539 - accuracy: 0.6212\nEpoch 3/10\n12/12 [==============================] - 20s 2s/step - loss: 0.8811 - accuracy: 0.6964\nEpoch 4/10\n12/12 [==============================] - 20s 2s/step - loss: 0.8207 - accuracy: 0.7075\nEpoch 5/10\n12/12 [==============================] - 20s 2s/step - loss: 0.8088 - accuracy: 0.6936\nEpoch 6/10\n12/12 [==============================] - 20s 2s/step - loss: 0.8122 - accuracy: 0.7075\nEpoch 7/10\n12/12 [==============================] - 19s 2s/step - loss: 0.8640 - accuracy: 0.6741\nEpoch 8/10\n12/12 [==============================] - 20s 2s/step - loss: 0.6402 - accuracy: 0.7744\nEpoch 9/10\n12/12 [==============================] - 20s 2s/step - loss: 0.6586 - accuracy: 0.7577\nEpoch 10/10\n12/12 [==============================] - 20s 2s/step - loss: 0.5684 - accuracy: 0.8022\n","output_type":"stream"}]},{"cell_type":"code","source":"train_loss, train_accuracy = model.evaluate(train_generator, steps=len(train_generator))\n\nprint(f\"Training Loss: {train_loss:.4f}\")\nprint(f\"Training Accuracy: {train_accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-01T17:15:36.068252Z","iopub.execute_input":"2023-09-01T17:15:36.068662Z","iopub.status.idle":"2023-09-01T17:15:52.486756Z","shell.execute_reply.started":"2023-09-01T17:15:36.068625Z","shell.execute_reply":"2023-09-01T17:15:52.485862Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"12/12 [==============================] - 15s 1s/step - loss: 0.5345 - accuracy: 0.7967\nTraining Loss: 0.5345\nTraining Accuracy: 0.7967\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save('/kaggle/working/myFruitclassifier001')  ","metadata":{"execution":{"iopub.status.busy":"2023-09-01T17:11:46.498784Z","iopub.execute_input":"2023-09-01T17:11:46.499119Z","iopub.status.idle":"2023-09-01T17:11:48.212980Z","shell.execute_reply.started":"2023-09-01T17:11:46.499089Z","shell.execute_reply":"2023-09-01T17:11:48.212090Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# from IPython.display import FileLinks\n# #\n# # Create a download link for the model file\n# FileLinks('/kaggle/working/myFruitclassifier001') ","metadata":{"execution":{"iopub.status.busy":"2023-09-01T17:11:48.215910Z","iopub.execute_input":"2023-09-01T17:11:48.216498Z","iopub.status.idle":"2023-09-01T17:11:48.220875Z","shell.execute_reply.started":"2023-09-01T17:11:48.216464Z","shell.execute_reply":"2023-09-01T17:11:48.219834Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# import zipfile\n\n# # Define the path to your SavedModel directory\n# saved_model_dir = '/kaggle/working/myFruitclassifier001'\n\n# # Define the name of the ZIP archive\n# zip_filename = '/kaggle/working/myFruitclassifier001.zip'\n\n# # Create a ZIP archive of the SavedModel directory\n# with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n#     for root, dirs, files in os.walk(saved_model_dir):\n#         for file in files:\n#             zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), saved_model_dir))\n\n# zip_filename  \n","metadata":{"execution":{"iopub.status.busy":"2023-09-01T17:11:48.222251Z","iopub.execute_input":"2023-09-01T17:11:48.222810Z","iopub.status.idle":"2023-09-01T17:11:48.235678Z","shell.execute_reply.started":"2023-09-01T17:11:48.222759Z","shell.execute_reply":"2023-09-01T17:11:48.234378Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# from IPython.display import FileLink\n\n# FileLink(zip_filename)","metadata":{"execution":{"iopub.status.busy":"2023-09-01T17:11:48.237437Z","iopub.execute_input":"2023-09-01T17:11:48.237839Z","iopub.status.idle":"2023-09-01T17:11:48.253840Z","shell.execute_reply.started":"2023-09-01T17:11:48.237783Z","shell.execute_reply":"2023-09-01T17:11:48.252494Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\nimport numpy as np\n\ndef predict_fruit_class(image_path, model_path='/kaggle/working/myFruitclassifier001'):\n    # Load the trained model\n    model = tf.keras.models.load_model(model_path)\n\n    # Load and preprocess the new image\n    img = image.load_img(image_path, target_size=(150, 150))\n    img_array = image.img_to_array(img)\n    img_array /= 255.0  # Normalize pixel values\n\n    # Expand dimensions to match the model's input shape\n    img_array = np.expand_dims(img_array, axis=0)\n\n    # Make predictions\n    predictions = model.predict(img_array)\n\n    # Get the predicted class index\n    predicted_class_index = np.argmax(predictions[0])\n\n    class_labels = ['apple fruit', 'banana fruit', 'cherry fruit', 'chickoo fruit', 'grapes fruit', 'kiwi fruit', 'mango fruit', 'orange fruit', 'strawberry fruit']\n\n    # Get the predicted class label\n    predicted_class_label = class_labels[predicted_class_index]\n\n    return predicted_class_label\n\n# Example usage:\nimage_path = '/kaggle/input/strawberry/three-strawberries-strawberry-leaf-white-background-114284301.jpg.webp'\npredicted_class = predict_fruit_class(image_path)\nprint(f\"Predicted Class: {predicted_class}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-01T17:11:48.255305Z","iopub.execute_input":"2023-09-01T17:11:48.256168Z","iopub.status.idle":"2023-09-01T17:11:49.321362Z","shell.execute_reply.started":"2023-09-01T17:11:48.256133Z","shell.execute_reply":"2023-09-01T17:11:49.320273Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 149ms/step\nPredicted Class: strawberry fruit\n","output_type":"stream"}]},{"cell_type":"code","source":"predict_fruit_class('/kaggle/input/strawberry/three-strawberries-strawberry-leaf-white-background-114284301.jpg.webp')","metadata":{"execution":{"iopub.status.busy":"2023-09-01T17:11:49.322768Z","iopub.execute_input":"2023-09-01T17:11:49.323419Z","iopub.status.idle":"2023-09-01T17:11:50.197687Z","shell.execute_reply.started":"2023-09-01T17:11:49.323384Z","shell.execute_reply":"2023-09-01T17:11:50.196455Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 105ms/step\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"'strawberry fruit'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}