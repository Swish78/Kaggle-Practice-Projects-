{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5514079,"sourceType":"datasetVersion","datasetId":3180206},{"sourceId":6392403,"sourceType":"datasetVersion","datasetId":3684772},{"sourceId":6397584,"sourceType":"datasetVersion","datasetId":3688316},{"sourceId":6397641,"sourceType":"datasetVersion","datasetId":3688357},{"sourceId":6398075,"sourceType":"datasetVersion","datasetId":3688659}],"dockerImageVersionId":30528,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/swish9/multi-class-classification-of-fruits-using-tf?scriptVersionId=179184873\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-05-22T18:09:16.330513Z","iopub.execute_input":"2024-05-22T18:09:16.331434Z","iopub.status.idle":"2024-05-22T18:09:16.341585Z","shell.execute_reply.started":"2024-05-22T18:09:16.331396Z","shell.execute_reply":"2024-05-22T18:09:16.340652Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense, Dropout, BatchNormalization, LeakyReLU\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.initializers import GlorotNormal","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-22T18:09:19.688925Z","iopub.execute_input":"2024-05-22T18:09:19.689663Z","iopub.status.idle":"2024-05-22T18:09:27.856041Z","shell.execute_reply.started":"2024-05-22T18:09:19.689624Z","shell.execute_reply":"2024-05-22T18:09:27.854923Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_dir = '/kaggle/input/fruits-dataset-images/images'","metadata":{"execution":{"iopub.status.busy":"2024-05-22T18:09:46.915858Z","iopub.execute_input":"2024-05-22T18:09:46.916644Z","iopub.status.idle":"2024-05-22T18:09:46.921587Z","shell.execute_reply.started":"2024-05-22T18:09:46.916606Z","shell.execute_reply":"2024-05-22T18:09:46.920424Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"img_width, img_height = 150, 150","metadata":{"execution":{"iopub.status.busy":"2024-05-22T18:09:50.642911Z","iopub.execute_input":"2024-05-22T18:09:50.643689Z","iopub.status.idle":"2024-05-22T18:09:50.647999Z","shell.execute_reply.started":"2024-05-22T18:09:50.643654Z","shell.execute_reply":"2024-05-22T18:09:50.647025Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1.0/255,\n    rotation_range=10,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T18:09:59.811703Z","iopub.execute_input":"2024-05-22T18:09:59.812444Z","iopub.status.idle":"2024-05-22T18:09:59.817436Z","shell.execute_reply.started":"2024-05-22T18:09:59.812412Z","shell.execute_reply":"2024-05-22T18:09:59.816347Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='categorical'\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T18:10:01.666897Z","iopub.execute_input":"2024-05-22T18:10:01.667654Z","iopub.status.idle":"2024-05-22T18:10:01.744744Z","shell.execute_reply.started":"2024-05-22T18:10:01.667621Z","shell.execute_reply":"2024-05-22T18:10:01.743904Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Found 359 images belonging to 9 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"model = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n    MaxPooling2D(2, 2),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D(2, 2),\n    Conv2D(128, (3, 3), activation='relu'),\n    MaxPooling2D(2, 2),\n    Flatten(),\n    Dense(512, activation='relu'),\n    Dense(9, activation='softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2024-05-22T18:10:04.102911Z","iopub.execute_input":"2024-05-22T18:10:04.103316Z","iopub.status.idle":"2024-05-22T18:10:06.65022Z","shell.execute_reply.started":"2024-05-22T18:10:04.103283Z","shell.execute_reply":"2024-05-22T18:10:06.649108Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"**I tried using He and Glorot Initialization techniques for weights, but I was getting accuracies around 0.6 to 0.7. However, with random initialization, my highest accuracy was 0.84**","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-05-22T18:10:33.887488Z","iopub.execute_input":"2024-05-22T18:10:33.888302Z","iopub.status.idle":"2024-05-22T18:10:33.906864Z","shell.execute_reply.started":"2024-05-22T18:10:33.888265Z","shell.execute_reply":"2024-05-22T18:10:33.906087Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def scheduler(epoch, lr):\n    if epoch < 10:\n        return lr\n    else:\n        return lr * tf.math.exp(-0.1)\n    \nlr_sch = tf.keras.callbacks.LearningRateScheduler(scheduler)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T18:10:37.760478Z","iopub.execute_input":"2024-05-22T18:10:37.761078Z","iopub.status.idle":"2024-05-22T18:10:37.766105Z","shell.execute_reply.started":"2024-05-22T18:10:37.761047Z","shell.execute_reply":"2024-05-22T18:10:37.765164Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"num_epochs = 100\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=len(train_generator),\n    epochs=num_epochs,\n    verbose=1,\n    callbacks=[lr_sch]\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T18:10:41.179064Z","iopub.execute_input":"2024-05-22T18:10:41.179452Z","iopub.status.idle":"2024-05-22T18:32:12.63035Z","shell.execute_reply.started":"2024-05-22T18:10:41.179423Z","shell.execute_reply":"2024-05-22T18:32:12.62943Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/100\n12/12 [==============================] - 24s 2s/step - loss: 3.2658 - accuracy: 0.1950 - lr: 0.0010\nEpoch 2/100\n12/12 [==============================] - 12s 1s/step - loss: 2.0423 - accuracy: 0.3844 - lr: 0.0010\nEpoch 3/100\n12/12 [==============================] - 12s 1s/step - loss: 2.9312 - accuracy: 0.4178 - lr: 0.0010\nEpoch 4/100\n12/12 [==============================] - 12s 1s/step - loss: 3.7422 - accuracy: 0.3900 - lr: 0.0010\nEpoch 5/100\n12/12 [==============================] - 13s 1s/step - loss: 3.1499 - accuracy: 0.4791 - lr: 0.0010\nEpoch 6/100\n12/12 [==============================] - 13s 1s/step - loss: 3.5997 - accuracy: 0.4735 - lr: 0.0010\nEpoch 7/100\n12/12 [==============================] - 12s 1s/step - loss: 1.8102 - accuracy: 0.5070 - lr: 0.0010\nEpoch 8/100\n12/12 [==============================] - 13s 1s/step - loss: 2.9968 - accuracy: 0.5097 - lr: 0.0010\nEpoch 9/100\n12/12 [==============================] - 12s 1s/step - loss: 1.6942 - accuracy: 0.5237 - lr: 0.0010\nEpoch 10/100\n12/12 [==============================] - 12s 1s/step - loss: 2.6196 - accuracy: 0.5822 - lr: 0.0010\nEpoch 11/100\n12/12 [==============================] - 13s 1s/step - loss: 1.5886 - accuracy: 0.5655 - lr: 9.0484e-04\nEpoch 12/100\n12/12 [==============================] - 12s 1s/step - loss: 2.0285 - accuracy: 0.6045 - lr: 8.1873e-04\nEpoch 13/100\n12/12 [==============================] - 12s 1s/step - loss: 1.9788 - accuracy: 0.5822 - lr: 7.4082e-04\nEpoch 14/100\n12/12 [==============================] - 12s 901ms/step - loss: 1.5572 - accuracy: 0.6267 - lr: 6.7032e-04\nEpoch 15/100\n12/12 [==============================] - 13s 1s/step - loss: 1.3342 - accuracy: 0.6769 - lr: 6.0653e-04\nEpoch 16/100\n12/12 [==============================] - 12s 969ms/step - loss: 1.3008 - accuracy: 0.6657 - lr: 5.4881e-04\nEpoch 17/100\n12/12 [==============================] - 13s 1s/step - loss: 0.9932 - accuracy: 0.7187 - lr: 4.9659e-04\nEpoch 18/100\n12/12 [==============================] - 13s 1s/step - loss: 0.7583 - accuracy: 0.7465 - lr: 4.4933e-04\nEpoch 19/100\n12/12 [==============================] - 12s 966ms/step - loss: 0.7352 - accuracy: 0.7465 - lr: 4.0657e-04\nEpoch 20/100\n12/12 [==============================] - 12s 1s/step - loss: 0.9566 - accuracy: 0.7604 - lr: 3.6788e-04\nEpoch 21/100\n12/12 [==============================] - 12s 1s/step - loss: 0.7479 - accuracy: 0.8106 - lr: 3.3287e-04\nEpoch 22/100\n12/12 [==============================] - 12s 1s/step - loss: 0.6787 - accuracy: 0.8273 - lr: 3.0119e-04\nEpoch 23/100\n12/12 [==============================] - 13s 1s/step - loss: 0.6142 - accuracy: 0.8245 - lr: 2.7253e-04\nEpoch 24/100\n12/12 [==============================] - 12s 1s/step - loss: 0.5272 - accuracy: 0.8301 - lr: 2.4660e-04\nEpoch 25/100\n12/12 [==============================] - 12s 1s/step - loss: 0.6213 - accuracy: 0.8162 - lr: 2.2313e-04\nEpoch 26/100\n12/12 [==============================] - 12s 1s/step - loss: 0.5413 - accuracy: 0.8329 - lr: 2.0190e-04\nEpoch 27/100\n12/12 [==============================] - 12s 1s/step - loss: 0.4921 - accuracy: 0.8635 - lr: 1.8268e-04\nEpoch 28/100\n12/12 [==============================] - 12s 1s/step - loss: 0.5021 - accuracy: 0.8579 - lr: 1.6530e-04\nEpoch 29/100\n12/12 [==============================] - 13s 1s/step - loss: 0.4479 - accuracy: 0.8524 - lr: 1.4957e-04\nEpoch 30/100\n12/12 [==============================] - 13s 1s/step - loss: 0.5713 - accuracy: 0.8496 - lr: 1.3534e-04\nEpoch 31/100\n12/12 [==============================] - 13s 1s/step - loss: 0.4045 - accuracy: 0.8830 - lr: 1.2246e-04\nEpoch 32/100\n12/12 [==============================] - 13s 1s/step - loss: 0.4647 - accuracy: 0.8886 - lr: 1.1080e-04\nEpoch 33/100\n12/12 [==============================] - 14s 1s/step - loss: 0.6236 - accuracy: 0.8384 - lr: 1.0026e-04\nEpoch 34/100\n12/12 [==============================] - 13s 1s/step - loss: 0.4754 - accuracy: 0.8468 - lr: 9.0718e-05\nEpoch 35/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3501 - accuracy: 0.8858 - lr: 8.2085e-05\nEpoch 36/100\n12/12 [==============================] - 13s 1s/step - loss: 0.4586 - accuracy: 0.8663 - lr: 7.4273e-05\nEpoch 37/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3464 - accuracy: 0.8914 - lr: 6.7205e-05\nEpoch 38/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3660 - accuracy: 0.8635 - lr: 6.0810e-05\nEpoch 39/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3183 - accuracy: 0.9136 - lr: 5.5023e-05\nEpoch 40/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3544 - accuracy: 0.8830 - lr: 4.9787e-05\nEpoch 41/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3820 - accuracy: 0.8858 - lr: 4.5049e-05\nEpoch 42/100\n12/12 [==============================] - 14s 1s/step - loss: 0.3724 - accuracy: 0.8914 - lr: 4.0762e-05\nEpoch 43/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3476 - accuracy: 0.9081 - lr: 3.6883e-05\nEpoch 44/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3460 - accuracy: 0.9025 - lr: 3.3373e-05\nEpoch 45/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3633 - accuracy: 0.8942 - lr: 3.0197e-05\nEpoch 46/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3708 - accuracy: 0.9192 - lr: 2.7324e-05\nEpoch 47/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3855 - accuracy: 0.9025 - lr: 2.4723e-05\nEpoch 48/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3241 - accuracy: 0.9109 - lr: 2.2371e-05\nEpoch 49/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3499 - accuracy: 0.8942 - lr: 2.0242e-05\nEpoch 50/100\n12/12 [==============================] - 13s 1s/step - loss: 0.4158 - accuracy: 0.8830 - lr: 1.8316e-05\nEpoch 51/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3235 - accuracy: 0.8969 - lr: 1.6573e-05\nEpoch 52/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3294 - accuracy: 0.8942 - lr: 1.4996e-05\nEpoch 53/100\n12/12 [==============================] - 14s 1s/step - loss: 0.2953 - accuracy: 0.9192 - lr: 1.3569e-05\nEpoch 54/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3031 - accuracy: 0.9081 - lr: 1.2277e-05\nEpoch 55/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3597 - accuracy: 0.8830 - lr: 1.1109e-05\nEpoch 56/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3148 - accuracy: 0.9025 - lr: 1.0052e-05\nEpoch 57/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3278 - accuracy: 0.8997 - lr: 9.0953e-06\nEpoch 58/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3166 - accuracy: 0.9164 - lr: 8.2297e-06\nEpoch 59/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3253 - accuracy: 0.8886 - lr: 7.4466e-06\nEpoch 60/100\n12/12 [==============================] - 14s 1s/step - loss: 0.3418 - accuracy: 0.9025 - lr: 6.7379e-06\nEpoch 61/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3253 - accuracy: 0.8997 - lr: 6.0967e-06\nEpoch 62/100\n12/12 [==============================] - 14s 1s/step - loss: 0.2934 - accuracy: 0.9220 - lr: 5.5165e-06\nEpoch 63/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3222 - accuracy: 0.9025 - lr: 4.9916e-06\nEpoch 64/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3437 - accuracy: 0.9025 - lr: 4.5166e-06\nEpoch 65/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3106 - accuracy: 0.8997 - lr: 4.0868e-06\nEpoch 66/100\n12/12 [==============================] - 12s 995ms/step - loss: 0.3302 - accuracy: 0.9081 - lr: 3.6979e-06\nEpoch 67/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3260 - accuracy: 0.8969 - lr: 3.3460e-06\nEpoch 68/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3387 - accuracy: 0.9053 - lr: 3.0275e-06\nEpoch 69/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3187 - accuracy: 0.9025 - lr: 2.7394e-06\nEpoch 70/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3404 - accuracy: 0.9248 - lr: 2.4787e-06\nEpoch 71/100\n12/12 [==============================] - 12s 1s/step - loss: 0.3834 - accuracy: 0.8969 - lr: 2.2429e-06\nEpoch 72/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3503 - accuracy: 0.9025 - lr: 2.0294e-06\nEpoch 73/100\n12/12 [==============================] - 12s 1s/step - loss: 0.3109 - accuracy: 0.9081 - lr: 1.8363e-06\nEpoch 74/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3251 - accuracy: 0.9164 - lr: 1.6616e-06\nEpoch 75/100\n12/12 [==============================] - 12s 1s/step - loss: 0.3312 - accuracy: 0.9192 - lr: 1.5034e-06\nEpoch 76/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3315 - accuracy: 0.9025 - lr: 1.3604e-06\nEpoch 77/100\n12/12 [==============================] - 13s 1s/step - loss: 0.2996 - accuracy: 0.9248 - lr: 1.2309e-06\nEpoch 78/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3046 - accuracy: 0.9136 - lr: 1.1138e-06\nEpoch 79/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3537 - accuracy: 0.9053 - lr: 1.0078e-06\nEpoch 80/100\n12/12 [==============================] - 12s 988ms/step - loss: 0.3158 - accuracy: 0.9081 - lr: 9.1188e-07\nEpoch 81/100\n12/12 [==============================] - 13s 1s/step - loss: 0.2721 - accuracy: 0.9248 - lr: 8.2510e-07\nEpoch 82/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3099 - accuracy: 0.9109 - lr: 7.4658e-07\nEpoch 83/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3075 - accuracy: 0.9248 - lr: 6.7554e-07\nEpoch 84/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3227 - accuracy: 0.9053 - lr: 6.1125e-07\nEpoch 85/100\n12/12 [==============================] - 13s 1s/step - loss: 0.2774 - accuracy: 0.9248 - lr: 5.5308e-07\nEpoch 86/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3239 - accuracy: 0.8858 - lr: 5.0045e-07\nEpoch 87/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3163 - accuracy: 0.9136 - lr: 4.5283e-07\nEpoch 88/100\n12/12 [==============================] - 12s 1s/step - loss: 0.4018 - accuracy: 0.9136 - lr: 4.0973e-07\nEpoch 89/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3043 - accuracy: 0.9136 - lr: 3.7074e-07\nEpoch 90/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3710 - accuracy: 0.8969 - lr: 3.3546e-07\nEpoch 91/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3234 - accuracy: 0.9081 - lr: 3.0354e-07\nEpoch 92/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3629 - accuracy: 0.8997 - lr: 2.7465e-07\nEpoch 93/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3002 - accuracy: 0.8997 - lr: 2.4852e-07\nEpoch 94/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3215 - accuracy: 0.9053 - lr: 2.2487e-07\nEpoch 95/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3241 - accuracy: 0.8942 - lr: 2.0347e-07\nEpoch 96/100\n12/12 [==============================] - 13s 1s/step - loss: 0.3266 - accuracy: 0.8997 - lr: 1.8410e-07\nEpoch 97/100\n12/12 [==============================] - 14s 1s/step - loss: 0.4026 - accuracy: 0.9109 - lr: 1.6659e-07\nEpoch 98/100\n12/12 [==============================] - 12s 1s/step - loss: 0.3011 - accuracy: 0.9081 - lr: 1.5073e-07\nEpoch 99/100\n12/12 [==============================] - 12s 1s/step - loss: 0.3824 - accuracy: 0.8969 - lr: 1.3639e-07\nEpoch 100/100\n12/12 [==============================] - 12s 1s/step - loss: 0.3278 - accuracy: 0.9081 - lr: 1.2341e-07\n","output_type":"stream"}]},{"cell_type":"code","source":"train_loss, train_accuracy = model.evaluate(train_generator, steps=len(train_generator))\n\nprint(f\"Training Loss: {train_loss:.4f}\")\nprint(f\"Training Accuracy: {train_accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-22T18:34:04.498767Z","iopub.execute_input":"2024-05-22T18:34:04.499752Z","iopub.status.idle":"2024-05-22T18:34:18.929871Z","shell.execute_reply.started":"2024-05-22T18:34:04.499715Z","shell.execute_reply":"2024-05-22T18:34:18.928755Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"12/12 [==============================] - 13s 1s/step - loss: 0.3048 - accuracy: 0.9164\nTraining Loss: 0.3048\nTraining Accuracy: 0.9164\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save('/kaggle/working/myFruitclassifier001.h5')  ","metadata":{"execution":{"iopub.status.busy":"2024-05-22T18:46:21.624556Z","iopub.execute_input":"2024-05-22T18:46:21.62497Z","iopub.status.idle":"2024-05-22T18:46:22.139676Z","shell.execute_reply.started":"2024-05-22T18:46:21.624933Z","shell.execute_reply":"2024-05-22T18:46:22.138766Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\nimport numpy as np\n\ndef predict_fruit_class(image_path, model_path='/kaggle/working/myFruitclassifier001'):\n    model = tf.keras.models.load_model(model_path)\n    img = image.load_img(image_path, target_size=(150, 150))\n    img_array = image.img_to_array(img)\n    img_array /= 255.0 \n    img_array = np.expand_dims(img_array, axis=0)\n    predictions = model.predict(img_array)\n    predicted_class_index = np.argmax(predictions[0])\n    class_labels = ['apple fruit', 'banana fruit', 'cherry fruit', 'chickoo fruit', 'grapes fruit', 'kiwi fruit', 'mango fruit', 'orange fruit', 'strawberry fruit']\n    predicted_class_label = class_labels[predicted_class_index]\n\n    return predicted_class_label\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T18:34:30.442997Z","iopub.execute_input":"2024-05-22T18:34:30.443902Z","iopub.status.idle":"2024-05-22T18:34:30.451403Z","shell.execute_reply.started":"2024-05-22T18:34:30.443865Z","shell.execute_reply":"2024-05-22T18:34:30.450209Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"predict_fruit_class('/kaggle/input/fruits-dataset-images/images/orange fruit/Image_10.jpg')","metadata":{"execution":{"iopub.status.busy":"2024-05-22T18:35:46.023704Z","iopub.execute_input":"2024-05-22T18:35:46.024081Z","iopub.status.idle":"2024-05-22T18:35:46.912667Z","shell.execute_reply.started":"2024-05-22T18:35:46.024051Z","shell.execute_reply":"2024-05-22T18:35:46.911583Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 88ms/step\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"'orange fruit'"},"metadata":{}}]},{"cell_type":"code","source":"predict_fruit_class('/kaggle/input/validation-banana/Banana-Single.jpg')","metadata":{"execution":{"iopub.status.busy":"2024-05-22T18:34:45.73075Z","iopub.execute_input":"2024-05-22T18:34:45.731178Z","iopub.status.idle":"2024-05-22T18:34:47.019383Z","shell.execute_reply.started":"2024-05-22T18:34:45.731142Z","shell.execute_reply":"2024-05-22T18:34:47.018187Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 90ms/step\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"'grapes fruit'"},"metadata":{}}]},{"cell_type":"code","source":"predict_fruit_class('/kaggle/input/fruits-dataset-images/images/strawberry fruit/Image_13.jpg')","metadata":{"execution":{"iopub.status.busy":"2024-05-22T18:35:59.729036Z","iopub.execute_input":"2024-05-22T18:35:59.729455Z","iopub.status.idle":"2024-05-22T18:36:00.629919Z","shell.execute_reply.started":"2024-05-22T18:35:59.729421Z","shell.execute_reply":"2024-05-22T18:36:00.628938Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 94ms/step\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"'strawberry fruit'"},"metadata":{}}]},{"cell_type":"code","source":"def add_block_1(model, first_block=False):\n    if first_block:\n        model.add(Conv2D(32, (3, 3), padding='same', input_shape=(img_width, img_height, 3)))\n    else:\n        model.add(Conv2D(32, (3, 3), padding='same'))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32, (3, 3), padding='same'))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32, (3, 3), padding='same'))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n\ndef add_block_2(model):\n    model.add(Conv2D(64, (3, 3), padding='same'))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n\ndef add_block_3(model):\n    model.add(Conv2D(128, (3, 3), padding='same'))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    model.add(Conv2D(128, (3, 3), padding='same'))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    model.add(Conv2D(128, (3, 3), padding='same'))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))","metadata":{"execution":{"iopub.status.busy":"2024-05-22T19:20:52.472855Z","iopub.execute_input":"2024-05-22T19:20:52.473408Z","iopub.status.idle":"2024-05-22T19:20:52.486986Z","shell.execute_reply.started":"2024-05-22T19:20:52.473367Z","shell.execute_reply":"2024-05-22T19:20:52.485917Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# Initialize the model\nmy_model = Sequential()\n\n# Repeat Blocks to add depth\nadd_block_1(my_model, first_block=True)\nadd_block_2(my_model)\nadd_block_1(my_model)\nadd_block_2(my_model)\nadd_block_3(my_model)\nadd_block_3(my_model)\nadd_block_3(my_model)\n\n# Flatten the output to feed into dense layers\nmy_model.add(Flatten())\n\n# Fully connected layers\nmy_model.add(Dense(512, activation='relu'))\nmy_model.add(Dropout(0.5))\nmy_model.add(Dense(256, activation='relu'))\nmy_model.add(Dropout(0.5))\nmy_model.add(Dense(128, activation='relu'))\nmy_model.add(Dropout(0.5))\nmy_model.add(Dense(9, activation='softmax')) \n\nmy_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision(name='precision'),\n                  tf.keras.metrics.Recall(name='recall'),\n                  tf.keras.metrics.AUC(name='auc'),\n                  tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy')])\nmy_model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T19:21:22.303689Z","iopub.execute_input":"2024-05-22T19:21:22.304084Z","iopub.status.idle":"2024-05-22T19:21:23.202611Z","shell.execute_reply.started":"2024-05-22T19:21:22.30405Z","shell.execute_reply":"2024-05-22T19:21:23.201534Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Model: \"sequential_3\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_41 (Conv2D)          (None, 150, 150, 32)      896       \n                                                                 \n leaky_re_lu_34 (LeakyReLU)  (None, 150, 150, 32)      0         \n                                                                 \n batch_normalization_34 (Bat  (None, 150, 150, 32)     128       \n chNormalization)                                                \n                                                                 \n conv2d_42 (Conv2D)          (None, 150, 150, 32)      9248      \n                                                                 \n leaky_re_lu_35 (LeakyReLU)  (None, 150, 150, 32)      0         \n                                                                 \n batch_normalization_35 (Bat  (None, 150, 150, 32)     128       \n chNormalization)                                                \n                                                                 \n conv2d_43 (Conv2D)          (None, 150, 150, 32)      9248      \n                                                                 \n leaky_re_lu_36 (LeakyReLU)  (None, 150, 150, 32)      0         \n                                                                 \n batch_normalization_36 (Bat  (None, 150, 150, 32)     128       \n chNormalization)                                                \n                                                                 \n average_pooling2d_8 (Averag  (None, 75, 75, 32)       0         \n ePooling2D)                                                     \n                                                                 \n conv2d_44 (Conv2D)          (None, 75, 75, 64)        18496     \n                                                                 \n leaky_re_lu_37 (LeakyReLU)  (None, 75, 75, 64)        0         \n                                                                 \n batch_normalization_37 (Bat  (None, 75, 75, 64)       256       \n chNormalization)                                                \n                                                                 \n average_pooling2d_9 (Averag  (None, 38, 38, 64)       0         \n ePooling2D)                                                     \n                                                                 \n conv2d_45 (Conv2D)          (None, 38, 38, 32)        18464     \n                                                                 \n leaky_re_lu_38 (LeakyReLU)  (None, 38, 38, 32)        0         \n                                                                 \n batch_normalization_38 (Bat  (None, 38, 38, 32)       128       \n chNormalization)                                                \n                                                                 \n conv2d_46 (Conv2D)          (None, 38, 38, 32)        9248      \n                                                                 \n leaky_re_lu_39 (LeakyReLU)  (None, 38, 38, 32)        0         \n                                                                 \n batch_normalization_39 (Bat  (None, 38, 38, 32)       128       \n chNormalization)                                                \n                                                                 \n conv2d_47 (Conv2D)          (None, 38, 38, 32)        9248      \n                                                                 \n leaky_re_lu_40 (LeakyReLU)  (None, 38, 38, 32)        0         \n                                                                 \n batch_normalization_40 (Bat  (None, 38, 38, 32)       128       \n chNormalization)                                                \n                                                                 \n average_pooling2d_10 (Avera  (None, 19, 19, 32)       0         \n gePooling2D)                                                    \n                                                                 \n conv2d_48 (Conv2D)          (None, 19, 19, 64)        18496     \n                                                                 \n leaky_re_lu_41 (LeakyReLU)  (None, 19, 19, 64)        0         \n                                                                 \n batch_normalization_41 (Bat  (None, 19, 19, 64)       256       \n chNormalization)                                                \n                                                                 \n average_pooling2d_11 (Avera  (None, 10, 10, 64)       0         \n gePooling2D)                                                    \n                                                                 \n conv2d_49 (Conv2D)          (None, 10, 10, 128)       73856     \n                                                                 \n leaky_re_lu_42 (LeakyReLU)  (None, 10, 10, 128)       0         \n                                                                 \n batch_normalization_42 (Bat  (None, 10, 10, 128)      512       \n chNormalization)                                                \n                                                                 \n conv2d_50 (Conv2D)          (None, 10, 10, 128)       147584    \n                                                                 \n leaky_re_lu_43 (LeakyReLU)  (None, 10, 10, 128)       0         \n                                                                 \n batch_normalization_43 (Bat  (None, 10, 10, 128)      512       \n chNormalization)                                                \n                                                                 \n conv2d_51 (Conv2D)          (None, 10, 10, 128)       147584    \n                                                                 \n leaky_re_lu_44 (LeakyReLU)  (None, 10, 10, 128)       0         \n                                                                 \n batch_normalization_44 (Bat  (None, 10, 10, 128)      512       \n chNormalization)                                                \n                                                                 \n max_pooling2d_9 (MaxPooling  (None, 5, 5, 128)        0         \n 2D)                                                             \n                                                                 \n conv2d_52 (Conv2D)          (None, 5, 5, 128)         147584    \n                                                                 \n leaky_re_lu_45 (LeakyReLU)  (None, 5, 5, 128)         0         \n                                                                 \n batch_normalization_45 (Bat  (None, 5, 5, 128)        512       \n chNormalization)                                                \n                                                                 \n conv2d_53 (Conv2D)          (None, 5, 5, 128)         147584    \n                                                                 \n leaky_re_lu_46 (LeakyReLU)  (None, 5, 5, 128)         0         \n                                                                 \n batch_normalization_46 (Bat  (None, 5, 5, 128)        512       \n chNormalization)                                                \n                                                                 \n conv2d_54 (Conv2D)          (None, 5, 5, 128)         147584    \n                                                                 \n leaky_re_lu_47 (LeakyReLU)  (None, 5, 5, 128)         0         \n                                                                 \n batch_normalization_47 (Bat  (None, 5, 5, 128)        512       \n chNormalization)                                                \n                                                                 \n max_pooling2d_10 (MaxPoolin  (None, 3, 3, 128)        0         \n g2D)                                                            \n                                                                 \n conv2d_55 (Conv2D)          (None, 3, 3, 128)         147584    \n                                                                 \n leaky_re_lu_48 (LeakyReLU)  (None, 3, 3, 128)         0         \n                                                                 \n batch_normalization_48 (Bat  (None, 3, 3, 128)        512       \n chNormalization)                                                \n                                                                 \n conv2d_56 (Conv2D)          (None, 3, 3, 128)         147584    \n                                                                 \n leaky_re_lu_49 (LeakyReLU)  (None, 3, 3, 128)         0         \n                                                                 \n batch_normalization_49 (Bat  (None, 3, 3, 128)        512       \n chNormalization)                                                \n                                                                 \n conv2d_57 (Conv2D)          (None, 3, 3, 128)         147584    \n                                                                 \n leaky_re_lu_50 (LeakyReLU)  (None, 3, 3, 128)         0         \n                                                                 \n batch_normalization_50 (Bat  (None, 3, 3, 128)        512       \n chNormalization)                                                \n                                                                 \n max_pooling2d_11 (MaxPoolin  (None, 2, 2, 128)        0         \n g2D)                                                            \n                                                                 \n flatten_3 (Flatten)         (None, 512)               0         \n                                                                 \n dense_10 (Dense)            (None, 512)               262656    \n                                                                 \n dropout_6 (Dropout)         (None, 512)               0         \n                                                                 \n dense_11 (Dense)            (None, 256)               131328    \n                                                                 \n dropout_7 (Dropout)         (None, 256)               0         \n                                                                 \n dense_12 (Dense)            (None, 128)               32896     \n                                                                 \n dropout_8 (Dropout)         (None, 128)               0         \n                                                                 \n dense_13 (Dense)            (None, 9)                 1161      \n                                                                 \n=================================================================\nTotal params: 1,781,801\nTrainable params: 1,778,857\nNon-trainable params: 2,944\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"num_epochs = 100\nhistory = my_model.fit(\n    train_generator,\n    steps_per_epoch=len(train_generator),\n    epochs=num_epochs,\n    verbose=1,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T19:21:28.067651Z","iopub.execute_input":"2024-05-22T19:21:28.068484Z","iopub.status.idle":"2024-05-22T19:44:23.579925Z","shell.execute_reply.started":"2024-05-22T19:21:28.068445Z","shell.execute_reply":"2024-05-22T19:44:23.578766Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Epoch 1/100\n12/12 [==============================] - 28s 1s/step - loss: 3.1839 - accuracy: 0.1170 - precision: 0.1356 - recall: 0.0446 - auc: 0.4952 - categorical_accuracy: 0.1170\nEpoch 2/100\n12/12 [==============================] - 14s 1s/step - loss: 2.5609 - accuracy: 0.1086 - precision: 0.2093 - recall: 0.0251 - auc: 0.5242 - categorical_accuracy: 0.1086\nEpoch 3/100\n12/12 [==============================] - 13s 1s/step - loss: 2.3347 - accuracy: 0.1532 - precision: 0.3125 - recall: 0.0279 - auc: 0.5785 - categorical_accuracy: 0.1532\nEpoch 4/100\n12/12 [==============================] - 13s 1s/step - loss: 2.3115 - accuracy: 0.2061 - precision: 0.2821 - recall: 0.0306 - auc: 0.5952 - categorical_accuracy: 0.2061\nEpoch 5/100\n12/12 [==============================] - 13s 1s/step - loss: 2.1419 - accuracy: 0.2006 - precision: 0.3636 - recall: 0.0557 - auc: 0.6558 - categorical_accuracy: 0.2006\nEpoch 6/100\n12/12 [==============================] - 13s 1s/step - loss: 2.2210 - accuracy: 0.2228 - precision: 0.3818 - recall: 0.0585 - auc: 0.6451 - categorical_accuracy: 0.2228\nEpoch 7/100\n12/12 [==============================] - 13s 1s/step - loss: 2.0415 - accuracy: 0.2618 - precision: 0.4127 - recall: 0.0724 - auc: 0.7054 - categorical_accuracy: 0.2618\nEpoch 8/100\n12/12 [==============================] - 13s 1s/step - loss: 1.9737 - accuracy: 0.3064 - precision: 0.5692 - recall: 0.1031 - auc: 0.7225 - categorical_accuracy: 0.3064\nEpoch 9/100\n12/12 [==============================] - 13s 1s/step - loss: 1.9179 - accuracy: 0.2981 - precision: 0.4713 - recall: 0.1142 - auc: 0.7496 - categorical_accuracy: 0.2981\nEpoch 10/100\n12/12 [==============================] - 13s 1s/step - loss: 1.8292 - accuracy: 0.3538 - precision: 0.5377 - recall: 0.1588 - auc: 0.7849 - categorical_accuracy: 0.3538\nEpoch 11/100\n12/12 [==============================] - 13s 1s/step - loss: 1.9513 - accuracy: 0.3398 - precision: 0.4234 - recall: 0.1309 - auc: 0.7653 - categorical_accuracy: 0.3398\nEpoch 12/100\n12/12 [==============================] - 13s 1s/step - loss: 1.8890 - accuracy: 0.3315 - precision: 0.5059 - recall: 0.1198 - auc: 0.7592 - categorical_accuracy: 0.3315\nEpoch 13/100\n12/12 [==============================] - 13s 1s/step - loss: 1.7798 - accuracy: 0.3064 - precision: 0.4639 - recall: 0.1253 - auc: 0.7824 - categorical_accuracy: 0.3064\nEpoch 14/100\n12/12 [==============================] - 13s 1s/step - loss: 1.7346 - accuracy: 0.3788 - precision: 0.5673 - recall: 0.1643 - auc: 0.8025 - categorical_accuracy: 0.3788\nEpoch 15/100\n12/12 [==============================] - 13s 1s/step - loss: 1.6845 - accuracy: 0.4095 - precision: 0.5299 - recall: 0.1727 - auc: 0.8209 - categorical_accuracy: 0.4095\nEpoch 16/100\n12/12 [==============================] - 13s 1s/step - loss: 1.6598 - accuracy: 0.3760 - precision: 0.5631 - recall: 0.1616 - auc: 0.8234 - categorical_accuracy: 0.3760\nEpoch 17/100\n12/12 [==============================] - 13s 1s/step - loss: 1.6344 - accuracy: 0.4345 - precision: 0.6333 - recall: 0.2117 - auc: 0.8287 - categorical_accuracy: 0.4345\nEpoch 18/100\n12/12 [==============================] - 14s 1s/step - loss: 1.6387 - accuracy: 0.4011 - precision: 0.4694 - recall: 0.1922 - auc: 0.8338 - categorical_accuracy: 0.4011\nEpoch 19/100\n12/12 [==============================] - 13s 1s/step - loss: 1.6047 - accuracy: 0.3955 - precision: 0.5625 - recall: 0.1755 - auc: 0.8373 - categorical_accuracy: 0.3955\nEpoch 20/100\n12/12 [==============================] - 13s 1s/step - loss: 1.5508 - accuracy: 0.4067 - precision: 0.5725 - recall: 0.2089 - auc: 0.8440 - categorical_accuracy: 0.4067\nEpoch 21/100\n12/12 [==============================] - 14s 1s/step - loss: 1.5483 - accuracy: 0.4206 - precision: 0.6014 - recall: 0.2479 - auc: 0.8481 - categorical_accuracy: 0.4206\nEpoch 22/100\n12/12 [==============================] - 13s 1s/step - loss: 1.4640 - accuracy: 0.4178 - precision: 0.5809 - recall: 0.2201 - auc: 0.8616 - categorical_accuracy: 0.4178\nEpoch 23/100\n12/12 [==============================] - 14s 1s/step - loss: 1.4257 - accuracy: 0.4708 - precision: 0.6345 - recall: 0.2563 - auc: 0.8739 - categorical_accuracy: 0.4708\nEpoch 24/100\n12/12 [==============================] - 14s 1s/step - loss: 1.4587 - accuracy: 0.4596 - precision: 0.5800 - recall: 0.2423 - auc: 0.8719 - categorical_accuracy: 0.4596\nEpoch 25/100\n12/12 [==============================] - 13s 1s/step - loss: 1.3757 - accuracy: 0.4930 - precision: 0.6303 - recall: 0.2897 - auc: 0.8789 - categorical_accuracy: 0.4930\nEpoch 26/100\n12/12 [==============================] - 13s 1s/step - loss: 1.4752 - accuracy: 0.4540 - precision: 0.5714 - recall: 0.2563 - auc: 0.8683 - categorical_accuracy: 0.4540\nEpoch 27/100\n12/12 [==============================] - 13s 1s/step - loss: 1.7225 - accuracy: 0.4206 - precision: 0.5135 - recall: 0.2117 - auc: 0.8136 - categorical_accuracy: 0.4206\nEpoch 28/100\n12/12 [==============================] - 13s 1s/step - loss: 1.5315 - accuracy: 0.4429 - precision: 0.6509 - recall: 0.1922 - auc: 0.8483 - categorical_accuracy: 0.4429\nEpoch 29/100\n12/12 [==============================] - 13s 1s/step - loss: 1.4480 - accuracy: 0.4457 - precision: 0.6525 - recall: 0.2563 - auc: 0.8665 - categorical_accuracy: 0.4457\nEpoch 30/100\n12/12 [==============================] - 13s 1s/step - loss: 1.3756 - accuracy: 0.5042 - precision: 0.6628 - recall: 0.3175 - auc: 0.8792 - categorical_accuracy: 0.5042\nEpoch 31/100\n12/12 [==============================] - 13s 1s/step - loss: 1.4636 - accuracy: 0.4513 - precision: 0.6269 - recall: 0.2340 - auc: 0.8690 - categorical_accuracy: 0.4513\nEpoch 32/100\n12/12 [==============================] - 14s 1s/step - loss: 1.5582 - accuracy: 0.4067 - precision: 0.5564 - recall: 0.2061 - auc: 0.8460 - categorical_accuracy: 0.4067\nEpoch 33/100\n12/12 [==============================] - 14s 1s/step - loss: 1.4781 - accuracy: 0.4568 - precision: 0.6029 - recall: 0.2284 - auc: 0.8636 - categorical_accuracy: 0.4568\nEpoch 34/100\n12/12 [==============================] - 14s 1s/step - loss: 1.4695 - accuracy: 0.4513 - precision: 0.6000 - recall: 0.2507 - auc: 0.8705 - categorical_accuracy: 0.4513\nEpoch 35/100\n12/12 [==============================] - 14s 1s/step - loss: 1.5361 - accuracy: 0.4596 - precision: 0.5896 - recall: 0.2201 - auc: 0.8549 - categorical_accuracy: 0.4596\nEpoch 36/100\n12/12 [==============================] - 14s 1s/step - loss: 1.3277 - accuracy: 0.4958 - precision: 0.6258 - recall: 0.2702 - auc: 0.8904 - categorical_accuracy: 0.4958\nEpoch 37/100\n12/12 [==============================] - 14s 1s/step - loss: 1.4234 - accuracy: 0.4847 - precision: 0.5329 - recall: 0.2479 - auc: 0.8762 - categorical_accuracy: 0.4847\nEpoch 38/100\n12/12 [==============================] - 14s 1s/step - loss: 1.4143 - accuracy: 0.5070 - precision: 0.6329 - recall: 0.2786 - auc: 0.8780 - categorical_accuracy: 0.5070\nEpoch 39/100\n12/12 [==============================] - 14s 1s/step - loss: 1.2522 - accuracy: 0.5237 - precision: 0.6564 - recall: 0.2981 - auc: 0.9040 - categorical_accuracy: 0.5237\nEpoch 40/100\n12/12 [==============================] - 14s 1s/step - loss: 1.3422 - accuracy: 0.4819 - precision: 0.6000 - recall: 0.2841 - auc: 0.8861 - categorical_accuracy: 0.4819\nEpoch 41/100\n12/12 [==============================] - 14s 1s/step - loss: 1.2900 - accuracy: 0.5515 - precision: 0.6490 - recall: 0.3760 - auc: 0.9007 - categorical_accuracy: 0.5515\nEpoch 42/100\n12/12 [==============================] - 13s 1s/step - loss: 1.3380 - accuracy: 0.5404 - precision: 0.6754 - recall: 0.3593 - auc: 0.8944 - categorical_accuracy: 0.5404\nEpoch 43/100\n12/12 [==============================] - 14s 1s/step - loss: 1.2628 - accuracy: 0.5460 - precision: 0.6865 - recall: 0.3538 - auc: 0.9011 - categorical_accuracy: 0.5460\nEpoch 44/100\n12/12 [==============================] - 14s 1s/step - loss: 1.2441 - accuracy: 0.5432 - precision: 0.6978 - recall: 0.3538 - auc: 0.9041 - categorical_accuracy: 0.5432\nEpoch 45/100\n12/12 [==============================] - 14s 1s/step - loss: 1.3734 - accuracy: 0.5070 - precision: 0.6242 - recall: 0.2869 - auc: 0.8856 - categorical_accuracy: 0.5070\nEpoch 46/100\n12/12 [==============================] - 13s 1s/step - loss: 1.3111 - accuracy: 0.5292 - precision: 0.7169 - recall: 0.3315 - auc: 0.8949 - categorical_accuracy: 0.5292\nEpoch 47/100\n12/12 [==============================] - 14s 1s/step - loss: 1.1656 - accuracy: 0.5877 - precision: 0.7143 - recall: 0.3900 - auc: 0.9160 - categorical_accuracy: 0.5877\nEpoch 48/100\n12/12 [==============================] - 14s 1s/step - loss: 1.2949 - accuracy: 0.5209 - precision: 0.6526 - recall: 0.3454 - auc: 0.8956 - categorical_accuracy: 0.5209\nEpoch 49/100\n12/12 [==============================] - 14s 1s/step - loss: 1.2587 - accuracy: 0.5710 - precision: 0.6902 - recall: 0.3538 - auc: 0.9021 - categorical_accuracy: 0.5710\nEpoch 50/100\n12/12 [==============================] - 13s 1s/step - loss: 1.2202 - accuracy: 0.5543 - precision: 0.6940 - recall: 0.3538 - auc: 0.9077 - categorical_accuracy: 0.5543\nEpoch 51/100\n12/12 [==============================] - 13s 1s/step - loss: 1.1401 - accuracy: 0.5933 - precision: 0.7306 - recall: 0.3928 - auc: 0.9177 - categorical_accuracy: 0.5933\nEpoch 52/100\n12/12 [==============================] - 13s 1s/step - loss: 1.1312 - accuracy: 0.5599 - precision: 0.7254 - recall: 0.3900 - auc: 0.9191 - categorical_accuracy: 0.5599\nEpoch 53/100\n12/12 [==============================] - 13s 1s/step - loss: 1.1825 - accuracy: 0.5961 - precision: 0.7330 - recall: 0.4206 - auc: 0.9156 - categorical_accuracy: 0.5961\nEpoch 54/100\n12/12 [==============================] - 13s 1s/step - loss: 1.2019 - accuracy: 0.5543 - precision: 0.6537 - recall: 0.3733 - auc: 0.9119 - categorical_accuracy: 0.5543\nEpoch 55/100\n12/12 [==============================] - 14s 1s/step - loss: 1.1776 - accuracy: 0.5877 - precision: 0.7177 - recall: 0.4178 - auc: 0.9161 - categorical_accuracy: 0.5877\nEpoch 56/100\n12/12 [==============================] - 14s 1s/step - loss: 1.1885 - accuracy: 0.5543 - precision: 0.6763 - recall: 0.3900 - auc: 0.9099 - categorical_accuracy: 0.5543\nEpoch 57/100\n12/12 [==============================] - 13s 1s/step - loss: 1.3286 - accuracy: 0.5348 - precision: 0.6316 - recall: 0.3008 - auc: 0.8901 - categorical_accuracy: 0.5348\nEpoch 58/100\n12/12 [==============================] - 13s 1s/step - loss: 1.1663 - accuracy: 0.5905 - precision: 0.7513 - recall: 0.3955 - auc: 0.9194 - categorical_accuracy: 0.5905\nEpoch 59/100\n12/12 [==============================] - 13s 1s/step - loss: 1.1152 - accuracy: 0.5905 - precision: 0.7668 - recall: 0.4123 - auc: 0.9229 - categorical_accuracy: 0.5905\nEpoch 60/100\n12/12 [==============================] - 13s 1s/step - loss: 1.1424 - accuracy: 0.5961 - precision: 0.6968 - recall: 0.4290 - auc: 0.9231 - categorical_accuracy: 0.5961\nEpoch 61/100\n12/12 [==============================] - 13s 1s/step - loss: 1.2403 - accuracy: 0.5822 - precision: 0.7377 - recall: 0.3760 - auc: 0.9105 - categorical_accuracy: 0.5822\nEpoch 62/100\n12/12 [==============================] - 13s 1s/step - loss: 1.1597 - accuracy: 0.5961 - precision: 0.7250 - recall: 0.4039 - auc: 0.9157 - categorical_accuracy: 0.5961\nEpoch 63/100\n12/12 [==============================] - 13s 1s/step - loss: 1.2941 - accuracy: 0.5487 - precision: 0.6593 - recall: 0.3343 - auc: 0.8951 - categorical_accuracy: 0.5487\nEpoch 64/100\n12/12 [==============================] - 13s 1s/step - loss: 1.3038 - accuracy: 0.5404 - precision: 0.7115 - recall: 0.3092 - auc: 0.8990 - categorical_accuracy: 0.5404\nEpoch 65/100\n12/12 [==============================] - 13s 1s/step - loss: 1.2579 - accuracy: 0.5571 - precision: 0.7158 - recall: 0.3649 - auc: 0.9014 - categorical_accuracy: 0.5571\nEpoch 66/100\n12/12 [==============================] - 13s 1s/step - loss: 1.1642 - accuracy: 0.5655 - precision: 0.6952 - recall: 0.4067 - auc: 0.9186 - categorical_accuracy: 0.5655\nEpoch 67/100\n12/12 [==============================] - 14s 1s/step - loss: 1.0430 - accuracy: 0.6156 - precision: 0.7321 - recall: 0.4262 - auc: 0.9321 - categorical_accuracy: 0.6156\nEpoch 68/100\n12/12 [==============================] - 14s 1s/step - loss: 1.0550 - accuracy: 0.6240 - precision: 0.7545 - recall: 0.4708 - auc: 0.9302 - categorical_accuracy: 0.6240\nEpoch 69/100\n12/12 [==============================] - 14s 1s/step - loss: 1.2611 - accuracy: 0.5710 - precision: 0.6905 - recall: 0.4039 - auc: 0.9090 - categorical_accuracy: 0.5710\nEpoch 70/100\n12/12 [==============================] - 13s 1s/step - loss: 1.2756 - accuracy: 0.5487 - precision: 0.6978 - recall: 0.3538 - auc: 0.8983 - categorical_accuracy: 0.5487\nEpoch 71/100\n12/12 [==============================] - 14s 1s/step - loss: 1.1019 - accuracy: 0.5961 - precision: 0.7354 - recall: 0.3872 - auc: 0.9248 - categorical_accuracy: 0.5961\nEpoch 72/100\n12/12 [==============================] - 14s 1s/step - loss: 1.1968 - accuracy: 0.6072 - precision: 0.6996 - recall: 0.4345 - auc: 0.9193 - categorical_accuracy: 0.6072\nEpoch 73/100\n12/12 [==============================] - 13s 1s/step - loss: 1.0929 - accuracy: 0.6462 - precision: 0.7573 - recall: 0.4345 - auc: 0.9260 - categorical_accuracy: 0.6462\nEpoch 74/100\n12/12 [==============================] - 13s 1s/step - loss: 1.2998 - accuracy: 0.5822 - precision: 0.7006 - recall: 0.3454 - auc: 0.8973 - categorical_accuracy: 0.5822\nEpoch 75/100\n12/12 [==============================] - 14s 1s/step - loss: 1.1402 - accuracy: 0.6128 - precision: 0.7610 - recall: 0.3370 - auc: 0.9213 - categorical_accuracy: 0.6128\nEpoch 76/100\n12/12 [==============================] - 14s 1s/step - loss: 1.0765 - accuracy: 0.6435 - precision: 0.7602 - recall: 0.4150 - auc: 0.9295 - categorical_accuracy: 0.6435\nEpoch 77/100\n12/12 [==============================] - 14s 1s/step - loss: 0.9892 - accuracy: 0.6435 - precision: 0.7605 - recall: 0.5042 - auc: 0.9387 - categorical_accuracy: 0.6435\nEpoch 78/100\n12/12 [==============================] - 14s 1s/step - loss: 1.0439 - accuracy: 0.6100 - precision: 0.7418 - recall: 0.5042 - auc: 0.9330 - categorical_accuracy: 0.6100\nEpoch 79/100\n12/12 [==============================] - 13s 1s/step - loss: 1.2437 - accuracy: 0.5543 - precision: 0.7304 - recall: 0.4150 - auc: 0.9051 - categorical_accuracy: 0.5543\nEpoch 80/100\n12/12 [==============================] - 14s 1s/step - loss: 1.0856 - accuracy: 0.6072 - precision: 0.7892 - recall: 0.4067 - auc: 0.9279 - categorical_accuracy: 0.6072\nEpoch 81/100\n12/12 [==============================] - 14s 1s/step - loss: 1.0904 - accuracy: 0.6240 - precision: 0.7478 - recall: 0.4791 - auc: 0.9294 - categorical_accuracy: 0.6240\nEpoch 82/100\n12/12 [==============================] - 14s 1s/step - loss: 1.0303 - accuracy: 0.6602 - precision: 0.7738 - recall: 0.4763 - auc: 0.9351 - categorical_accuracy: 0.6602\nEpoch 83/100\n12/12 [==============================] - 14s 1s/step - loss: 1.1166 - accuracy: 0.6212 - precision: 0.7767 - recall: 0.4652 - auc: 0.9218 - categorical_accuracy: 0.6212\nEpoch 84/100\n12/12 [==============================] - 13s 1s/step - loss: 1.1396 - accuracy: 0.6212 - precision: 0.7711 - recall: 0.4318 - auc: 0.9290 - categorical_accuracy: 0.6212\nEpoch 85/100\n12/12 [==============================] - 13s 1s/step - loss: 0.9523 - accuracy: 0.6741 - precision: 0.7702 - recall: 0.5320 - auc: 0.9431 - categorical_accuracy: 0.6741\nEpoch 86/100\n12/12 [==============================] - 14s 1s/step - loss: 1.0525 - accuracy: 0.6351 - precision: 0.7447 - recall: 0.4875 - auc: 0.9299 - categorical_accuracy: 0.6351\nEpoch 87/100\n12/12 [==============================] - 13s 1s/step - loss: 1.1491 - accuracy: 0.6295 - precision: 0.7327 - recall: 0.4429 - auc: 0.9207 - categorical_accuracy: 0.6295\nEpoch 88/100\n12/12 [==============================] - 13s 1s/step - loss: 1.1490 - accuracy: 0.6240 - precision: 0.7179 - recall: 0.3900 - auc: 0.9188 - categorical_accuracy: 0.6240\nEpoch 89/100\n12/12 [==============================] - 13s 973ms/step - loss: 0.9378 - accuracy: 0.6852 - precision: 0.8065 - recall: 0.4875 - auc: 0.9463 - categorical_accuracy: 0.6852\nEpoch 90/100\n12/12 [==============================] - 13s 1s/step - loss: 0.9648 - accuracy: 0.6741 - precision: 0.7915 - recall: 0.5181 - auc: 0.9400 - categorical_accuracy: 0.6741\nEpoch 91/100\n12/12 [==============================] - 13s 1s/step - loss: 1.0704 - accuracy: 0.6323 - precision: 0.7406 - recall: 0.4930 - auc: 0.9279 - categorical_accuracy: 0.6323\nEpoch 92/100\n12/12 [==============================] - 13s 1s/step - loss: 1.0635 - accuracy: 0.6212 - precision: 0.7613 - recall: 0.4708 - auc: 0.9287 - categorical_accuracy: 0.6212\nEpoch 93/100\n12/12 [==============================] - 13s 1s/step - loss: 1.1124 - accuracy: 0.5961 - precision: 0.7411 - recall: 0.4067 - auc: 0.9241 - categorical_accuracy: 0.5961\nEpoch 94/100\n12/12 [==============================] - 14s 1s/step - loss: 1.0954 - accuracy: 0.6184 - precision: 0.7379 - recall: 0.4234 - auc: 0.9293 - categorical_accuracy: 0.6184\nEpoch 95/100\n12/12 [==============================] - 13s 1s/step - loss: 1.0772 - accuracy: 0.6295 - precision: 0.7564 - recall: 0.4930 - auc: 0.9281 - categorical_accuracy: 0.6295\nEpoch 96/100\n12/12 [==============================] - 13s 1s/step - loss: 1.3322 - accuracy: 0.5097 - precision: 0.6647 - recall: 0.3092 - auc: 0.8891 - categorical_accuracy: 0.5097\nEpoch 97/100\n12/12 [==============================] - 14s 1s/step - loss: 1.5648 - accuracy: 0.4958 - precision: 0.6803 - recall: 0.2312 - auc: 0.8442 - categorical_accuracy: 0.4958\nEpoch 98/100\n12/12 [==============================] - 14s 1s/step - loss: 1.5174 - accuracy: 0.4680 - precision: 0.7087 - recall: 0.2033 - auc: 0.8567 - categorical_accuracy: 0.4680\nEpoch 99/100\n12/12 [==============================] - 14s 1s/step - loss: 1.2950 - accuracy: 0.5627 - precision: 0.7351 - recall: 0.3092 - auc: 0.8981 - categorical_accuracy: 0.5627\nEpoch 100/100\n12/12 [==============================] - 13s 1s/step - loss: 1.3531 - accuracy: 0.4958 - precision: 0.6800 - recall: 0.2841 - auc: 0.8862 - categorical_accuracy: 0.4958\n","output_type":"stream"}]},{"cell_type":"code","source":"metrics = my_model.evaluate(train_generator, steps=len(train_generator))\ntrain_loss, train_accuracy, train_precision, train_recall, train_auc, train_categorical_accuracy = metrics\n\nprint(f\"Training Loss: {train_loss:.4f}\")\nprint(f\"Training Accuracy: {train_accuracy:.4f}\")\nprint(f\"Training Precision: {train_precision:.4f}\")\nprint(f\"Training Recall: {train_recall:.4f}\")\nprint(f\"Training AUC: {train_auc:.4f}\")\nprint(f\"Training Categorical Accuracy: {train_categorical_accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-22T19:51:32.710738Z","iopub.execute_input":"2024-05-22T19:51:32.711146Z","iopub.status.idle":"2024-05-22T19:51:47.1068Z","shell.execute_reply.started":"2024-05-22T19:51:32.711096Z","shell.execute_reply":"2024-05-22T19:51:47.105722Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"12/12 [==============================] - 13s 1s/step - loss: 2.9595 - accuracy: 0.3370 - precision: 0.5353 - recall: 0.2535 - auc: 0.7455 - categorical_accuracy: 0.3370\nTraining Loss: 2.9595\nTraining Accuracy: 0.3370\nTraining Precision: 0.5353\nTraining Recall: 0.2535\nTraining AUC: 0.7455\nTraining Categorical Accuracy: 0.3370\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}