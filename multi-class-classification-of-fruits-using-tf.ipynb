{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:48:04.680638Z","iopub.execute_input":"2023-09-01T16:48:04.681033Z","iopub.status.idle":"2023-09-01T16:48:04.692029Z","shell.execute_reply.started":"2023-09-01T16:48:04.681002Z","shell.execute_reply":"2023-09-01T16:48:04.691030Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\nfrom tensorflow.keras.initializers import GlorotNormal","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-01T16:48:04.694449Z","iopub.execute_input":"2023-09-01T16:48:04.695175Z","iopub.status.idle":"2023-09-01T16:48:20.714908Z","shell.execute_reply.started":"2023-09-01T16:48:04.695097Z","shell.execute_reply":"2023-09-01T16:48:20.713760Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_dir = '/kaggle/input/fruits-dataset-images/images'","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:48:20.722518Z","iopub.execute_input":"2023-09-01T16:48:20.723952Z","iopub.status.idle":"2023-09-01T16:48:20.730309Z","shell.execute_reply.started":"2023-09-01T16:48:20.723908Z","shell.execute_reply":"2023-09-01T16:48:20.728983Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1.0/255,\n    rotation_range=10,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:48:20.733837Z","iopub.execute_input":"2023-09-01T16:48:20.734209Z","iopub.status.idle":"2023-09-01T16:48:20.742088Z","shell.execute_reply.started":"2023-09-01T16:48:20.734174Z","shell.execute_reply":"2023-09-01T16:48:20.741173Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='categorical'\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:48:20.745005Z","iopub.execute_input":"2023-09-01T16:48:20.745506Z","iopub.status.idle":"2023-09-01T16:48:20.843465Z","shell.execute_reply.started":"2023-09-01T16:48:20.745472Z","shell.execute_reply":"2023-09-01T16:48:20.842590Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Found 359 images belonging to 9 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"model = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n    MaxPooling2D(2, 2),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D(2, 2),\n    Conv2D(128, (3, 3), activation='relu'),\n    MaxPooling2D(2, 2),\n    Flatten(),\n    Dense(512, activation='relu'),\n    Dense(9, activation='softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:48:20.844756Z","iopub.execute_input":"2023-09-01T16:48:20.845059Z","iopub.status.idle":"2023-09-01T16:48:26.756621Z","shell.execute_reply.started":"2023-09-01T16:48:20.845029Z","shell.execute_reply":"2023-09-01T16:48:26.755545Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"**I tried using He and Glorot Initialization techniques for weights, but I was getting accuracies around 0.6 to 0.7. However, with random initialization, my highest accuracy was 0.84**","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:48:26.758305Z","iopub.execute_input":"2023-09-01T16:48:26.758675Z","iopub.status.idle":"2023-09-01T16:48:26.778356Z","shell.execute_reply.started":"2023-09-01T16:48:26.758639Z","shell.execute_reply":"2023-09-01T16:48:26.777043Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"num_epochs = 10\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=len(train_generator),\n    epochs=num_epochs,\n    verbose=1\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:51:45.475319Z","iopub.execute_input":"2023-09-01T16:51:45.475694Z","iopub.status.idle":"2023-09-01T16:54:50.161902Z","shell.execute_reply.started":"2023-09-01T16:51:45.475661Z","shell.execute_reply":"2023-09-01T16:54:50.160724Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Epoch 1/10\n12/12 [==============================] - 15s 1s/step - loss: 1.2256 - accuracy: 0.5627\nEpoch 2/10\n12/12 [==============================] - 13s 1s/step - loss: 1.1145 - accuracy: 0.6100\nEpoch 3/10\n12/12 [==============================] - 13s 1s/step - loss: 0.8649 - accuracy: 0.7103\nEpoch 4/10\n12/12 [==============================] - 13s 1s/step - loss: 0.8956 - accuracy: 0.6769\nEpoch 5/10\n12/12 [==============================] - 13s 1s/step - loss: 0.8148 - accuracy: 0.7047\nEpoch 6/10\n12/12 [==============================] - 13s 1s/step - loss: 0.7674 - accuracy: 0.7465\nEpoch 7/10\n12/12 [==============================] - 13s 1s/step - loss: 0.7005 - accuracy: 0.7437\nEpoch 8/10\n12/12 [==============================] - 13s 1s/step - loss: 0.6169 - accuracy: 0.7883\nEpoch 9/10\n12/12 [==============================] - 13s 982ms/step - loss: 0.5367 - accuracy: 0.8189\nEpoch 10/10\n12/12 [==============================] - 13s 1s/step - loss: 0.5368 - accuracy: 0.8078\n","output_type":"stream"}]},{"cell_type":"code","source":"train_loss, train_accuracy = model.evaluate(train_generator, steps=len(train_generator))\n\nprint(f\"Training Loss: {train_loss:.4f}\")\nprint(f\"Training Accuracy: {train_accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:54:50.164535Z","iopub.execute_input":"2023-09-01T16:54:50.164973Z","iopub.status.idle":"2023-09-01T16:55:12.496868Z","shell.execute_reply.started":"2023-09-01T16:54:50.164933Z","shell.execute_reply":"2023-09-01T16:55:12.495587Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"12/12 [==============================] - 13s 1s/step - loss: 0.5106 - accuracy: 0.8134\nTraining Loss: 0.5106\nTraining Accuracy: 0.8134\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save('/kaggle/working/myFruitclassifier001')  ","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:51:31.577105Z","iopub.execute_input":"2023-09-01T16:51:31.577517Z","iopub.status.idle":"2023-09-01T16:51:33.611443Z","shell.execute_reply.started":"2023-09-01T16:51:31.577479Z","shell.execute_reply":"2023-09-01T16:51:33.610190Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# from IPython.display import FileLinks\n# #\n# # Create a download link for the model file\n# FileLinks('/kaggle/working/myFruitclassifier001') ","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:51:33.617143Z","iopub.execute_input":"2023-09-01T16:51:33.617481Z","iopub.status.idle":"2023-09-01T16:51:33.622086Z","shell.execute_reply.started":"2023-09-01T16:51:33.617451Z","shell.execute_reply":"2023-09-01T16:51:33.621053Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# import zipfile\n\n# # Define the path to your SavedModel directory\n# saved_model_dir = '/kaggle/working/myFruitclassifier001'\n\n# # Define the name of the ZIP archive\n# zip_filename = '/kaggle/working/myFruitclassifier001.zip'\n\n# # Create a ZIP archive of the SavedModel directory\n# with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n#     for root, dirs, files in os.walk(saved_model_dir):\n#         for file in files:\n#             zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), saved_model_dir))\n\n# zip_filename  \n","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:51:33.623671Z","iopub.execute_input":"2023-09-01T16:51:33.624323Z","iopub.status.idle":"2023-09-01T16:51:33.634964Z","shell.execute_reply.started":"2023-09-01T16:51:33.624284Z","shell.execute_reply":"2023-09-01T16:51:33.633844Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# from IPython.display import FileLink\n\n# FileLink(zip_filename)","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:51:33.638072Z","iopub.execute_input":"2023-09-01T16:51:33.638765Z","iopub.status.idle":"2023-09-01T16:51:33.654976Z","shell.execute_reply.started":"2023-09-01T16:51:33.638727Z","shell.execute_reply":"2023-09-01T16:51:33.653988Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# import streamlit as st\n# import tensorflow as tf\n\n# # Load the TensorFlow SavedModel\n# model_path = '/kaggle/working/myFruitclassifier001'  # Path to the directory containing saved_model.pb and variables/\n# loaded_model = tf.saved_model.load(model_path)\n\n# # Function to make predictions\n# @st.cache(allow_output_mutation=True)\n# def predict(image_path):\n#     img = tf.image.decode_image(tf.io.read_file(image_path))\n#     img = tf.image.resize(img, (150, 150))  # Resize to match the model's input shape\n#     img = tf.expand_dims(img, axis=0)\n#     prediction = loaded_model(img)\n#     return prediction\n\n# # Streamlit app\n# st.title(\"Fruit Image Classifier\")\n\n# # File uploader\n# uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n\n# if uploaded_file is not None:\n#     st.image(uploaded_file, caption=\"Uploaded Image\", use_column_width=True)\n#     prediction = predict(uploaded_file)\n    \n#     # Add code to interpret the prediction and display the result\n#     # For example, you can use class labels and probabilities to display the predicted class.\n\n# # Optionally, you can add other features to your Streamlit app, such as displaying the predicted class and probability.","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:51:35.841339Z","iopub.execute_input":"2023-09-01T16:51:35.841715Z","iopub.status.idle":"2023-09-01T16:51:35.849679Z","shell.execute_reply.started":"2023-09-01T16:51:35.841670Z","shell.execute_reply":"2023-09-01T16:51:35.847198Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# !pip install streamlit","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:51:35.851420Z","iopub.execute_input":"2023-09-01T16:51:35.852581Z","iopub.status.idle":"2023-09-01T16:51:35.860937Z","shell.execute_reply.started":"2023-09-01T16:51:35.852538Z","shell.execute_reply":"2023-09-01T16:51:35.859500Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# streamline(myModel,img)","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:51:36.003105Z","iopub.execute_input":"2023-09-01T16:51:36.004069Z","iopub.status.idle":"2023-09-01T16:51:36.011966Z","shell.execute_reply.started":"2023-09-01T16:51:36.004026Z","shell.execute_reply":"2023-09-01T16:51:36.011043Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\nimport numpy as np\n\ndef predict_fruit_class(image_path, model_path='/kaggle/working/myFruitclassifier001'):\n    # Load the trained model\n    model = tf.keras.models.load_model(model_path)\n\n    # Load and preprocess the new image\n    img = image.load_img(image_path, target_size=(150, 150))\n    img_array = image.img_to_array(img)\n    img_array /= 255.0  # Normalize pixel values\n\n    # Expand dimensions to match the model's input shape\n    img_array = np.expand_dims(img_array, axis=0)\n\n    # Make predictions\n    predictions = model.predict(img_array)\n\n    # Get the predicted class index\n    predicted_class_index = np.argmax(predictions[0])\n\n    class_labels = ['apple fruit', 'banana fruit', 'cherry fruit', 'chickoo fruit', 'grapes fruit', 'kiwi fruit', 'mango fruit', 'orange fruit', 'strawberry fruit']\n\n    # Get the predicted class label\n    predicted_class_label = class_labels[predicted_class_index]\n\n    return predicted_class_label\n\n# Example usage:\nimage_path = '/kaggle/input/strawberry/three-strawberries-strawberry-leaf-white-background-114284301.jpg.webp'\npredicted_class = predict_fruit_class(image_path)\nprint(f\"Predicted Class: {predicted_class}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:56:43.020215Z","iopub.execute_input":"2023-09-01T16:56:43.020578Z","iopub.status.idle":"2023-09-01T16:56:44.191200Z","shell.execute_reply.started":"2023-09-01T16:56:43.020549Z","shell.execute_reply":"2023-09-01T16:56:44.189782Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 83ms/step\nPredicted Class: strawberry fruit\n","output_type":"stream"}]},{"cell_type":"code","source":"predict_fruit_class('/kaggle/input/strawberry/three-strawberries-strawberry-leaf-white-background-114284301.jpg.webp')","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:58:04.975536Z","iopub.execute_input":"2023-09-01T16:58:04.975931Z","iopub.status.idle":"2023-09-01T16:58:05.790023Z","shell.execute_reply.started":"2023-09-01T16:58:04.975896Z","shell.execute_reply":"2023-09-01T16:58:05.788820Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 80ms/step\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"'strawberry fruit'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}