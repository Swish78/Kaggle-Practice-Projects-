{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:48:04.680638Z","iopub.execute_input":"2023-09-01T16:48:04.681033Z","iopub.status.idle":"2023-09-01T16:48:04.692029Z","shell.execute_reply.started":"2023-09-01T16:48:04.681002Z","shell.execute_reply":"2023-09-01T16:48:04.691030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\nfrom tensorflow.keras.initializers import GlorotNormal","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-01T16:48:04.694449Z","iopub.execute_input":"2023-09-01T16:48:04.695175Z","iopub.status.idle":"2023-09-01T16:48:20.714908Z","shell.execute_reply.started":"2023-09-01T16:48:04.695097Z","shell.execute_reply":"2023-09-01T16:48:20.713760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir = '/kaggle/input/fruits-dataset-images/images'","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:48:20.722518Z","iopub.execute_input":"2023-09-01T16:48:20.723952Z","iopub.status.idle":"2023-09-01T16:48:20.730309Z","shell.execute_reply.started":"2023-09-01T16:48:20.723908Z","shell.execute_reply":"2023-09-01T16:48:20.728983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1.0/255,\n    rotation_range=10,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:48:20.733837Z","iopub.execute_input":"2023-09-01T16:48:20.734209Z","iopub.status.idle":"2023-09-01T16:48:20.742088Z","shell.execute_reply.started":"2023-09-01T16:48:20.734174Z","shell.execute_reply":"2023-09-01T16:48:20.741173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='categorical'\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:48:20.745005Z","iopub.execute_input":"2023-09-01T16:48:20.745506Z","iopub.status.idle":"2023-09-01T16:48:20.843465Z","shell.execute_reply.started":"2023-09-01T16:48:20.745472Z","shell.execute_reply":"2023-09-01T16:48:20.842590Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n    MaxPooling2D(2, 2),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D(2, 2),\n    Conv2D(128, (3, 3), activation='relu'),\n    MaxPooling2D(2, 2),\n    Flatten(),\n    Dense(512, activation='relu'),\n    Dense(9, activation='softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:48:20.844756Z","iopub.execute_input":"2023-09-01T16:48:20.845059Z","iopub.status.idle":"2023-09-01T16:48:26.756621Z","shell.execute_reply.started":"2023-09-01T16:48:20.845029Z","shell.execute_reply":"2023-09-01T16:48:26.755545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**I tried using He and Glorot Initialization techniques for weights, but I was getting accuracies around 0.6 to 0.7. However, with random initialization, my highest accuracy was 0.84**","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:48:26.758305Z","iopub.execute_input":"2023-09-01T16:48:26.758675Z","iopub.status.idle":"2023-09-01T16:48:26.778356Z","shell.execute_reply.started":"2023-09-01T16:48:26.758639Z","shell.execute_reply":"2023-09-01T16:48:26.777043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 10\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=len(train_generator),\n    epochs=num_epochs,\n    verbose=1\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:51:45.475319Z","iopub.execute_input":"2023-09-01T16:51:45.475694Z","iopub.status.idle":"2023-09-01T16:54:50.161902Z","shell.execute_reply.started":"2023-09-01T16:51:45.475661Z","shell.execute_reply":"2023-09-01T16:54:50.160724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss, train_accuracy = model.evaluate(train_generator, steps=len(train_generator))\n\nprint(f\"Training Loss: {train_loss:.4f}\")\nprint(f\"Training Accuracy: {train_accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:54:50.164535Z","iopub.execute_input":"2023-09-01T16:54:50.164973Z","iopub.status.idle":"2023-09-01T16:55:12.496868Z","shell.execute_reply.started":"2023-09-01T16:54:50.164933Z","shell.execute_reply":"2023-09-01T16:55:12.495587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('/kaggle/working/myFruitclassifier001')  ","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:51:31.577105Z","iopub.execute_input":"2023-09-01T16:51:31.577517Z","iopub.status.idle":"2023-09-01T16:51:33.611443Z","shell.execute_reply.started":"2023-09-01T16:51:31.577479Z","shell.execute_reply":"2023-09-01T16:51:33.610190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from IPython.display import FileLinks\n# #\n# # Create a download link for the model file\n# FileLinks('/kaggle/working/myFruitclassifier001') ","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:51:33.617143Z","iopub.execute_input":"2023-09-01T16:51:33.617481Z","iopub.status.idle":"2023-09-01T16:51:33.622086Z","shell.execute_reply.started":"2023-09-01T16:51:33.617451Z","shell.execute_reply":"2023-09-01T16:51:33.621053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import zipfile\n\n# # Define the path to your SavedModel directory\n# saved_model_dir = '/kaggle/working/myFruitclassifier001'\n\n# # Define the name of the ZIP archive\n# zip_filename = '/kaggle/working/myFruitclassifier001.zip'\n\n# # Create a ZIP archive of the SavedModel directory\n# with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n#     for root, dirs, files in os.walk(saved_model_dir):\n#         for file in files:\n#             zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), saved_model_dir))\n\n# zip_filename  \n","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:51:33.623671Z","iopub.execute_input":"2023-09-01T16:51:33.624323Z","iopub.status.idle":"2023-09-01T16:51:33.634964Z","shell.execute_reply.started":"2023-09-01T16:51:33.624284Z","shell.execute_reply":"2023-09-01T16:51:33.633844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from IPython.display import FileLink\n\n# FileLink(zip_filename)","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:51:33.638072Z","iopub.execute_input":"2023-09-01T16:51:33.638765Z","iopub.status.idle":"2023-09-01T16:51:33.654976Z","shell.execute_reply.started":"2023-09-01T16:51:33.638727Z","shell.execute_reply":"2023-09-01T16:51:33.653988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\nimport numpy as np\n\ndef predict_fruit_class(image_path, model_path='/kaggle/working/myFruitclassifier001'):\n    # Load the trained model\n    model = tf.keras.models.load_model(model_path)\n\n    # Load and preprocess the new image\n    img = image.load_img(image_path, target_size=(150, 150))\n    img_array = image.img_to_array(img)\n    img_array /= 255.0  # Normalize pixel values\n\n    # Expand dimensions to match the model's input shape\n    img_array = np.expand_dims(img_array, axis=0)\n\n    # Make predictions\n    predictions = model.predict(img_array)\n\n    # Get the predicted class index\n    predicted_class_index = np.argmax(predictions[0])\n\n    class_labels = ['apple fruit', 'banana fruit', 'cherry fruit', 'chickoo fruit', 'grapes fruit', 'kiwi fruit', 'mango fruit', 'orange fruit', 'strawberry fruit']\n\n    # Get the predicted class label\n    predicted_class_label = class_labels[predicted_class_index]\n\n    return predicted_class_label\n\n# Example usage:\nimage_path = '/kaggle/input/strawberry/three-strawberries-strawberry-leaf-white-background-114284301.jpg.webp'\npredicted_class = predict_fruit_class(image_path)\nprint(f\"Predicted Class: {predicted_class}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:56:43.020215Z","iopub.execute_input":"2023-09-01T16:56:43.020578Z","iopub.status.idle":"2023-09-01T16:56:44.191200Z","shell.execute_reply.started":"2023-09-01T16:56:43.020549Z","shell.execute_reply":"2023-09-01T16:56:44.189782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_fruit_class('/kaggle/input/strawberry/three-strawberries-strawberry-leaf-white-background-114284301.jpg.webp')","metadata":{"execution":{"iopub.status.busy":"2023-09-01T16:58:04.975536Z","iopub.execute_input":"2023-09-01T16:58:04.975931Z","iopub.status.idle":"2023-09-01T16:58:05.790023Z","shell.execute_reply.started":"2023-09-01T16:58:04.975896Z","shell.execute_reply":"2023-09-01T16:58:05.788820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}